[{"content":"Lua - Basics for x = 0, 10, 1 do print(x) end -- for loop with range and step. step if not given is assumed to be 1 -- Tables are the soul of Lua. They double up as arrays and hashes a = {} b = {1, 2, 3} b[1] -- b[1] will return 1 as indexing for arrays is from 1 c = {[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7}} -- We can have a \u0026#34;0\u0026#34;th index by adding the 1st element as [0]=value -- Adding keys which are not valid identifiers in Lua needs to be done by wrapping key in [] -- If a key is a valid identifier, we can access using `.` e.g c.a for above code vs c[0] for k,v in pairs(c) do print(type(k)) end -- iterates through k/v in table and prints type of key Print a table as valid Lua code function printTable(tbl) -- Specify function vars as local else they become global local s = \u0026#34;{\u0026#34; local fst = true for k,v in pairs(tbl) do local tk = type(k) local tv = type(v) if not fst then s = s .. \u0026#34;,\u0026#34; else fst = false end if tk == \u0026#34;number\u0026#34; or tk == \u0026#34;boolean\u0026#34; then s = s .. \u0026#34;[\u0026#34; .. tostring(k) .. \u0026#34;]=\u0026#34; else s = s .. \u0026#39;[\u0026#34;\u0026#39; .. k .. \u0026#39;\u0026#34;]=\u0026#39; end if tv == \u0026#34;table\u0026#34; then s = s .. printTable(v) elseif tv == \u0026#34;number\u0026#34; or tv == \u0026#34;boolean\u0026#34; then s = s .. tostring(v) elseif tv == \u0026#34;string\u0026#34; then s = s .. \u0026#39;\u0026#34;\u0026#39; .. v .. \u0026#39;\u0026#34;\u0026#39; else s = s .. vt end end s = s .. \u0026#34;}\u0026#34; return s end sv = printTable({[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7},[true]=123}) print(sv) -- posts.lua (saved table) can be read from another lua file as posts=require(\u0026#34;posts\u0026#34;) return {[0]={[1]=123,[2]=3},[\u0026#34;v\u0026#34;]={[1]=2,[2]=6,[3]=7},[\u0026#34;a\u0026#34;]={[1]=1,[2]=2,[3]=3},[true]=123} ","permalink":"https://rrampage.github.io/2021/12/04/relearning-lua/","summary":"Lua - Basics for x = 0, 10, 1 do print(x) end -- for loop with range and step. step if not given is assumed to be 1 -- Tables are the soul of Lua. They double up as arrays and hashes a = {} b = {1, 2, 3} b[1] -- b[1] will return 1 as indexing for arrays is from 1 c = {[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7}} -- We can have a \u0026#34;0\u0026#34;th index by adding the 1st element as [0]=value -- Adding keys which are not valid identifiers in Lua needs to be done by wrapping key in [] -- If a key is a valid identifier, we can access using `.` e.g c.a for above code vs c[0] for k,v in pairs(c) do print(type(k)) end -- iterates through k/v in table and prints type of key Print a table as valid Lua code function printTable(tbl) -- Specify function vars as local else they become global local s = \u0026#34;{\u0026#34; local fst = true for k,v in pairs(tbl) do local tk = type(k) local tv = type(v) if not fst then s = s .","title":"Re-learning Lua"},{"content":"This series is a summary of Oracle\u0026rsquo;s JVM troubleshooting course which gives an overview on JVM memory management, Hotspot VM\u0026rsquo;s garbage collection options, various memory errors and how to troubleshoot them.\nIn this post (part 1), we will have a look at how JVM manages memory and its different garbage collectors.\nYou can find Part 2 here\nJVM Memory Management Overview The JVM provides automatic memory management to free the programmer from manually managing memory. New objects are allocated on heap memory. A root set consists of pointers to external memory, static variables, threads, JNI references and internal JVM structures. Objects directly reachable from the root set must be kept in heap. Objects reachable from any of the reachable objects must also be in heap. This group of objects are the only ones which can be used by a program. The unreachable objects (garbage) are removed using a process called garbage collection (GC). Reachable objects are compacted i.e moved to contiguous space in heap. This is important as otherwise, the heap will become fragmented.\nGenerational GC and Memory Spaces in Hotspot When the JVM starts, it requests some memory from the OS. This memory is divided into various spaces.\nMemory spaces in JVM prior to JDK 8\nSeparate pools hold objects of diff age ranges JVM\u0026rsquo;s GC is generational and is based on the hypothesis that: Most objects die young Few references from older to younger objects There are 2 generations of objects: young : small and collected frequently (minor collection). Objects which survive a threshold number of GCs move to old generation. old : large, collected infrequently (major collection = Full GC) Prior to JDK 8, there was also a permanent generation which was for storing class representations and metadata, interned strings and class statics. This was replaced by meta-space in JDK 8 and later. Meta-space is allocated in native memory. It is managed through JVM options MetaspaceSize for initial size and MaxMetaspaceSize for maximum. If UseCompressedClassPointers is enabled, 2 areas of memory are used for storing classes and their metadata - meta-space and compressed class space. 64 bit class pointers represented with 32 bit offsets to save space. Class metadata is referenced by 32 bit offsets stored in compressed class space. By default, compressed class space is 1 GB. Code cache is used to store compiled code generated by JIT (Just in time optimizer), allocated out of native memory and managed by Code Cache Sweeper Garbage Collectors in Hotspot JVM The JVM has different garbage collection methods for different generations of objects. Some of them are described below:\nYoung generation collection Serial - Stop-the-world (STW), copying collector, single threaded ParNew - STW, copying collector, multiple GC threads Parallel Scavenge - STW, copying collector, multiple GC threads Old generation collection Serial Old - STW, mark-sweep-compact collector, single threaded CMS - Mostly concurrent, low pause Parallel Old - compacting collector, multiple GC threads G1 : designed for large heaps and offers predictable short pauses. Has different memory layout for generations Same collector for all generations GC options for JDK These are the option flags passed to JVM for specifying which GC to use:\nUseSerialGC : Serial + SerialOld UseParNewGC : ParNew + SerialOld . In JDK 9, uses CMS for old gen UseConcMarkSweepGC : ParNew + CMS + SerialOld CMS used most of time to collect old generation. SerialOld used when concurrent mode failure occurs. CMS performs most work in concurrent with application threads. No heap compaction leads to fragmentation. Has floating garbage and requires larger heap sizes. Free space maintained as linked lists. Allocation expensive compared to bump-the-pointer allocations. Additional overhead on young collections Deprecated in JDK 9 UseParallelGC : Parallel Scavenge + Parallel Old. Maximizes throughput. Default GC till JDK 9 UseG1GC - G1 for both generations Server style GC for multi-core machines with large memory Low GC pauses with high probability while trying for high throughput Compacting collector. Low pauses without fragmentation Better GC ergonomics. Parallel threads and some tasks are concurrent with application threads Available since JDK 7u4 and default in JDK 9 For more detailed information on tuning the garbage collector, read the official GC Tuning Guide\nMinor GC or How young generation is collected: When Eden space in young gen is full, reachable objects are marked and moved to the ToSurvivorSpace Objects in FromSurvivor space that are reachable are moved to ToSurvivorSpace Objects in FromSurvivor space that have crossed the threshold are promoted to the old generation Eden becomes empty and is ready for new allocations To and From Survivor Spaces are switched Notes on Mark-Sweep-Compact collector (Serial Old): Mark phase : marks all live objects Sweep phase : sweeps over heap identifying garbage Slide phase : GC performs a sliding compaction by sliding live objects to the start of the heap ","permalink":"https://rrampage.github.io/2018/05/15/a-primer-on-jvm-memory-management-and-troubleshooting-1/","summary":"This series is a summary of Oracle\u0026rsquo;s JVM troubleshooting course which gives an overview on JVM memory management, Hotspot VM\u0026rsquo;s garbage collection options, various memory errors and how to troubleshoot them.\nIn this post (part 1), we will have a look at how JVM manages memory and its different garbage collectors.\nYou can find Part 2 here\nJVM Memory Management Overview The JVM provides automatic memory management to free the programmer from manually managing memory. New objects are allocated on heap memory. A root set consists of pointers to external memory, static variables, threads, JNI references and internal JVM structures. Objects directly reachable from the root set must be kept in heap. Objects reachable from any of the reachable objects must also be in heap. This group of objects are the only ones which can be used by a program. The unreachable objects (garbage) are removed using a process called garbage collection (GC). Reachable objects are compacted i.e moved to contiguous space in heap.","title":"A Primer on JVM Memory Management and Troubleshooting - 1"},{"content":"Snake case and Camel case are conventions of naming variables, functions and classes. Most teams and projects prescribe a particular case in their style guides.\nExamples of camel case:\nMyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher Examples of snake case:\nadd matrix_add diagonal_matrix_add pseudo_inverse If we want to convert back and forth between these cases, we must look for the points of interest - the word boundaries. Camel case boundaries have the first letter capitalized while the snake case word boundaries have an _.\nSnake case to camel case Here is a regular expression for finding out the _ and the first letter in the next word:\n(.*?)_([a-zA-Z]) This regex has 2 parts:\n(.*?) finds everything upto the _.\nThe \u0026lsquo;.\u0026rsquo; means any character. \u0026lsquo;*\u0026rsquo; stands for match 0 or more instances \u0026lsquo;?\u0026rsquo; stands for non-greedy match. We must use \u0026lsquo;?\u0026rsquo; in the pattern because the regex engine will try to match as much as possible by default. So, if we use just (.*), the whole word will be consumed and nothing will be left for the rest of the pattern. \u0026lsquo;()\u0026rsquo; stand for a group. A group is a way of saving a part of the match for later. Together, they mean that find all characters upto the first \u0026lsquo;_\u0026rsquo; and capture them in a group. ([a-zA-Z]) finds the first alphabet after the _. We need this to convert to upper case for Camel case.\nThe Python code below converts words which are in snake case to camel case:\nimport re REG = r\u0026#34;(.*?)_([a-zA-Z])\u0026#34; def camel(match): return match.group(1) + match.group(2).upper() def camel_upper(match): return match.group(1)[0].upper() + match.group(1)[1:] + match.group(2).upper() words = \u0026#34;\u0026#34;\u0026#34;add matrix_add diagonal_matrix_add pseudo_inverse\u0026#34;\u0026#34;\u0026#34;.splitlines() results = [re.sub(REG, camel, w, 0) for w in words] print(results) # Output: # [\u0026#39;add\u0026#39;, \u0026#39;matrixAdd\u0026#39;, \u0026#39;diagonalMatrixAdd\u0026#39;, \u0026#39;pseudoInverse\u0026#39;] We use the regex we constructed earlier and the re.sub method to substitute our matched words. We pass a method called camel as an argument. This method allows us to change the case of the letter in the second group and keep the first group unchanged. Notice that the first letter can be either lower or upper depending on whether it is a variable or method (lower) or a class (upper). The camel_upper method can be used for class names.\nCamel case to snake case Similarly, for converting from camel to snake case, the regex is:\n(.+?)([A-Z]) And the Python code :\nimport re REG = r\u0026#34;(.+?)([A-Z])\u0026#34; def snake(match): return match.group(1).lower() + \u0026#34;_\u0026#34; + match.group(2).lower() words = \u0026#34;\u0026#34;\u0026#34;MyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher\u0026#34;\u0026#34;\u0026#34;.splitlines() results = [re.sub(REG, snake, w, 0) for w in words] print(results) # Output # [\u0026#39;my_class\u0026#39;, \u0026#39;my_class_factory\u0026#39;, \u0026#39;my_class_factory_builder\u0026#39;, \u0026#39;my_class_factory_builder_impl\u0026#39;, \u0026#39;my_instance\u0026#39;, \u0026#39;my_instance2\u0026#39;, \u0026#39;abc\u0026#39;, \u0026#39;pattern_matcher\u0026#39;] ","permalink":"https://rrampage.github.io/2018/05/09/snake-case-to-camel-case-and-back-using-regular-expressions-and-python/","summary":"Snake case and Camel case are conventions of naming variables, functions and classes. Most teams and projects prescribe a particular case in their style guides.\nExamples of camel case:\nMyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher Examples of snake case:\nadd matrix_add diagonal_matrix_add pseudo_inverse If we want to convert back and forth between these cases, we must look for the points of interest - the word boundaries. Camel case boundaries have the first letter capitalized while the snake case word boundaries have an _.\nSnake case to camel case Here is a regular expression for finding out the _ and the first letter in the next word:\n(.*?)_([a-zA-Z]) This regex has 2 parts:\n(.*?) finds everything upto the _.\nThe \u0026lsquo;.\u0026rsquo; means any character. \u0026lsquo;*\u0026rsquo; stands for match 0 or more instances \u0026lsquo;?\u0026rsquo; stands for non-greedy match. We must use \u0026lsquo;?\u0026rsquo; in the pattern because the regex engine will try to match as much as possible by default. So, if we use just (.","title":"Snake case to camel case and back using regular expressions and Python"},{"content":"Background Today, I resumed a rust project of mine after a long time. In order to check my last working code, I ran cargo run. But it refused to run with error message:\n....\u0026#34;-Wl,-Bdynamic\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;dl\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;gcc_s\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;c\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;m\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; = note: /usr/bin/ld: cannot find Scrt1.o: No such file or directory collect2: error: ld returned 1 exit status Linker Issues! ld is used to link libraries. So, the error was not in the code but in the linking phase. I googled the error and the solution was to have build-essential package installed. But the package was already installed on my machine (it is one of the first packages I install on any development machine).\nSome more googling revealed that cargo uses the system cc linker to link to the C runtime. Running which cc gave me $HOME/anaconda3/bin/cc. This cc is part of my Anaconda root environment. (Anaconda is a package manager for scientific computing packages. It is a convenient way for installing multiple versions of packages in different environments).\nOn Linux, the linker knows where to find the required libraries using the shared library cache. I ran ldconfig -v to refresh it and then try again. Same error!\nIt is possible to explicitly list directories to include using LD_LIBRARY_PATH environment variable. I tried setting the LD_LIBRARY_PATH to point to the required directory and then run cargo as LD_LIBRARY_PATH=DIR cargo build -v. But it gave the same error.\nI thought that cargo must be setting the linker value somewhere, so instead let me try directly compiling with rustc. Even that gave the same error. With this, I eliminated the possibility of some environment variable only affecting cargo.\nMore googling! Further searching for the error with \u0026ldquo;rust\u0026rdquo; added showed me results of people having trouble cross-compiling. From this, I learned that cargo has different targets i.e different instruction sets (e,g x86-64, arm, x86, mips), different OSs (e.g linux, windows, freebsd) and different C runtimes (e.g glibc, musl, msvc). The Rust documentation on cargo mentioned that this is called a target triple. The Cargo book mentioned that you can direct cargo to explicitly use a particular linker using RUSTFLAGS environment variable.\nSince I am only building for my machine, I had to find out the exact value of the target. Rust gives an exhaustive list of all supported targets by running rustc --print target-list. My target was x86_64-unknown-linux-gnu.\nIt is possible to pass a linker to cargo explicitly as RUSTFLAGS=\u0026quot;-C linker=x86_64-unknown-linux-gnu\u0026quot; cargo build -v. It worked!\nAll-time fix! I do not want to do this every time I run cargo. The Cargo book says that cargo uses a global config file in $HOME/.cargo/config.\nI added the following to the file:\n# Specify which linker to use for this target [target.x86_64-unknown-linux-gnu] linker = \u0026#34;x86_64-linux-gnu-gcc\u0026#34; Now, cargo build works without issues.\n","permalink":"https://rrampage.github.io/2018/05/09/cargo-refused-to-build-my-project-a-rust-debugging-story/","summary":"Background Today, I resumed a rust project of mine after a long time. In order to check my last working code, I ran cargo run. But it refused to run with error message:\n....\u0026#34;-Wl,-Bdynamic\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;dl\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;gcc_s\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;c\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;m\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; = note: /usr/bin/ld: cannot find Scrt1.o: No such file or directory collect2: error: ld returned 1 exit status Linker Issues! ld is used to link libraries. So, the error was not in the code but in the linking phase. I googled the error and the solution was to have build-essential package installed. But the package was already installed on my machine (it is one of the first packages I install on any development machine).\nSome more googling revealed that cargo uses the system cc linker to link to the C runtime. Running which cc gave me $HOME/anaconda3/bin/cc. This cc is part of my Anaconda root environment.","title":"Cargo refused to build my project - A Rust debugging story!"},{"content":"Many times, smoothly running processes stop working mysteriously. You open the logs and see what is happening, only to find that even the logs have stopped updating. But the process itself is running. You SSH to the server and type cd TAB. Bash weeps \u0026ldquo;Unable to create temporary file\u0026rdquo;. The machine is out of disk space\u0026hellip;\nHere is a checklist to make disk space debugging easier, using standard Linux utilities so you can get started without having to install anything extra:\ndf -h command gives you an overview in a readable format about the number of disks mounted and their total and available capacities. To get an idea of which folders/directories are eating up the maximum space, try out du -ch / | sort -h | tail -n 30. This gives you the 30 most space consuming directories. If you already know which directories generate maximum disk output e.g logs and temp files, you can replace the \u0026lsquo;/\u0026rsquo; with your directory (DIR) and run the command as du -ch DIR | sort -h | tail -n 30 Now that we have identified the directories with maximum space consumed, we may need to delete some files and get our process going again. The rm command is your friend here. You can delete old logs and temporary files to free up space. Many times, the culprit is a single large file which is already in use by a program e.g catalina.out by Apache Tomcat. If you want to free up space without shutting down the process, the truncate command will help you out. Example: truncate -s0 BIG_LOG.log. This will truncate the file to 0 bytes and still allow the other process to use it without issues (standard Unix permissions apply) Sometimes, you delete files and still, the space does not seem to be recovered. This can be because some process is still holding on to the file descriptor of the deleted file. Once these processes are stopped, the space will be recovered. The lsof command will help you out here. It stands for list open files. You can find out which processes are using deleted files as follows: lsof | grep deleted | grep OLD_FILENAME. The lsof command gives you the process name and the process id so you can run kill on the process. If you do not know the name of the deleted file, you can still run lsof | grep deleted and see the output to check for any familiar file / process. Finally, keep in mind that disk space is one of the metrics you should monitor on your server. This checklist must be used in a pinch. If you find yourself constantly having disk space issues, the solution is to set up periodic deletion/rotation of old log files, alerts when the disk space reaches a particular threshold or to increase the disk size if your processes require a lot of disk space e.g Kafka, MySQL and other databases.\nLet me know if there are some other tools I am missing out on and your experiences dealing with disk space issues!\n","permalink":"https://rrampage.github.io/2018/05/04/disk-space-debugging-checklist/","summary":"Many times, smoothly running processes stop working mysteriously. You open the logs and see what is happening, only to find that even the logs have stopped updating. But the process itself is running. You SSH to the server and type cd TAB. Bash weeps \u0026ldquo;Unable to create temporary file\u0026rdquo;. The machine is out of disk space\u0026hellip;\nHere is a checklist to make disk space debugging easier, using standard Linux utilities so you can get started without having to install anything extra:\ndf -h command gives you an overview in a readable format about the number of disks mounted and their total and available capacities. To get an idea of which folders/directories are eating up the maximum space, try out du -ch / | sort -h | tail -n 30. This gives you the 30 most space consuming directories. If you already know which directories generate maximum disk output e.g logs and temp files, you can replace the \u0026lsquo;/\u0026rsquo; with your directory (DIR) and run the command as du -ch DIR | sort -h | tail -n 30 Now that we have identified the directories with maximum space consumed, we may need to delete some files and get our process going again.","title":"Disk Space Debugging Checklist"},{"content":"Hello World!\n","permalink":"https://rrampage.github.io/2014/03/03/hello-world/","summary":"Hello World!","title":"Hello World"},{"content":"About this blog: the delights and frustrations of programming new things I learn/stumble across while coding interesting concepts/resources I come across trying to explain a few topics About Me I am a software developer. I work on mostly backend stuff. I blog occasionally here or crosspost to dev.to. You can reach out to me via various websites in the footer.\n💬 Ask me about \u0026hellip; Bash, sed, awk, GNU Make, jq Java/Kotlin, JOOQ, Dropwizard Postgres Solr \u0026amp; Elasticsearch ArangoDB Nginx \u0026amp; Openresty Linux State machines, Regexes, State charts 📫 How to reach me: Github issues on this repo My DMs are open on dev.to LinkedIn Twitter ","permalink":"https://rrampage.github.io/about/","summary":"About this blog: the delights and frustrations of programming new things I learn/stumble across while coding interesting concepts/resources I come across trying to explain a few topics About Me I am a software developer. I work on mostly backend stuff. I blog occasionally here or crosspost to dev.to. You can reach out to me via various websites in the footer.\n💬 Ask me about \u0026hellip; Bash, sed, awk, GNU Make, jq Java/Kotlin, JOOQ, Dropwizard Postgres Solr \u0026amp; Elasticsearch ArangoDB Nginx \u0026amp; Openresty Linux State machines, Regexes, State charts 📫 How to reach me: Github issues on this repo My DMs are open on dev.to LinkedIn Twitter ","title":"About"}]