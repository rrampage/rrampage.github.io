[{"content":"Lua - Basics for x = 0, 10, 1 do print(x) end -- for loop with range and step. step if not given is assumed to be 1 -- Tables are the soul of Lua. They double up as arrays and hashes a = {} b = {1, 2, 3} b[1] -- b[1] will return 1 as indexing for arrays is from 1 c = {[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7}} -- We can have a \u0026#34;0\u0026#34;th index by adding the 1st element as [0]=value -- Adding keys which are not valid identifiers in Lua needs to be done by wrapping key in [] -- If a key is a valid identifier, we can access using `.` e.g c.a for above code vs c[0] for k,v in pairs(c) do print(type(k)) end -- iterates through k/v in table and prints type of key Print a table as valid Lua code function printTable(tbl) -- Specify function vars as local else they become global local s = \u0026#34;{\u0026#34; local fst = true for k,v in pairs(tbl) do local tk = type(k) local tv = type(v) if not fst then s = s .. \u0026#34;,\u0026#34; else fst = false end if tk == \u0026#34;number\u0026#34; or tk == \u0026#34;boolean\u0026#34; then s = s .. \u0026#34;[\u0026#34; .. tostring(k) .. \u0026#34;]=\u0026#34; else s = s .. \u0026#39;[\u0026#34;\u0026#39; .. k .. \u0026#39;\u0026#34;]=\u0026#39; end if tv == \u0026#34;table\u0026#34; then s = s .. printTable(v) elseif tv == \u0026#34;number\u0026#34; or tv == \u0026#34;boolean\u0026#34; then s = s .. tostring(v) elseif tv == \u0026#34;string\u0026#34; then s = s .. \u0026#39;\u0026#34;\u0026#39; .. v .. \u0026#39;\u0026#34;\u0026#39; else s = s .. vt end end s = s .. \u0026#34;}\u0026#34; return s end sv = printTable({[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7},[true]=123}) print(sv) -- posts.lua (saved table) can be read from another lua file as posts=require(\u0026#34;posts\u0026#34;) return {[0]={[1]=123,[2]=3},[\u0026#34;v\u0026#34;]={[1]=2,[2]=6,[3]=7},[\u0026#34;a\u0026#34;]={[1]=1,[2]=2,[3]=3},[true]=123} ","permalink":"https://rrampage.github.io/2021/12/04/relearning-lua/","summary":"Lua - Basics for x = 0, 10, 1 do print(x) end -- for loop with range and step. step if not given is assumed to be 1 -- Tables are the soul of Lua. They double up as arrays and hashes a = {} b = {1, 2, 3} b[1] -- b[1] will return 1 as indexing for arrays is from 1 c = {[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7}} -- We can have a \u0026#34;0\u0026#34;th index by adding the 1st element as [0]=value -- Adding keys which are not valid identifiers in Lua needs to be done by wrapping key in [] -- If a key is a valid identifier, we can access using `.` e.g c.a for above code vs c[0] for k,v in pairs(c) do print(type(k)) end -- iterates through k/v in table and prints type of key Print a table as valid Lua code function printTable(tbl) -- Specify function vars as local else they become global local s = \u0026#34;{\u0026#34; local fst = true for k,v in pairs(tbl) do local tk = type(k) local tv = type(v) if not fst then s = s .","title":"Re-learning Lua"},{"content":"Many times, we have shell scripts which perform some important stuff like inserting into database, mailing reports, etc which we want to run exactly one instance of.\nEnter locks! A simple solution is to create a \u0026ldquo;lock file\u0026rdquo; and check if the file exists when the script starts. If the file is already created, it means another instance of that program is running, so we can fail with message \u0026ldquo;Try again later!\u0026rdquo;. Once the script completes running, it will clean-up and delete the lock file.\nLOCK_FILE=a.lock if [ -f \u0026#34;$LOCK_FILE\u0026#34; ]; then # Lock file already exists, exit the script echo \u0026#34;An instance of this script is already running\u0026#34; exit 1 fi # Create the lock file echo \u0026#34;Locked\u0026#34; \u0026gt; \u0026#34;$LOCK_FILE\u0026#34; # Do the normal stuff # clean-up before exit rm \u0026#34;$LOCK_FILE\u0026#34; This looks promising but there are issues with this approach. What happens if the script does not end correctly i.e it exits because of some failure before it reaches the clean-up part of the code? Or if it gets forcibly terminated with Ctrl+C or kill command? In both these cases, the created lock file will not be deleted. So next time you run the script, you will always get an error and will have to manually delete the file.\nThere is another, more subtle error with the above code. A race condition. If two instances of scripts are started around the same time, it is possible that both of them get past the if [ -f \u0026quot;$LOCK_FILE\u0026quot; ] because the second instance may reach that part of the code before the first instance is able to create the lock file. Thus, we have more than one instance running.\nA better lock! Is there a way to create a lock file which is more robust to race conditions and non-standard termination (Ctrl+C, kill command, etc)? Linux offers flock a utility to manage locks from shell scripts. Using flock, we can rewrite the above snippet as follows:\nLOCK_FILE=a.lock exec 99\u0026gt;\u0026#34;$LOCK_FILE\u0026#34; flock -n 99 || exit 1 # Do stuff and exit! The exec 99\u0026gt;\u0026quot;$LOCK_FILE\u0026quot; creates a file descriptor numbered 99 and assigns it to LOCK_FILE. File descriptors (fd) 0, 1, 2 are for stdin, stdout, stderr respectively. We are creating new fd with a high number to ensure that it does not clash with numbered fds opened later-on by script.\nflock -n 99 || exit 1 does 2 things. Firstly, it acquires an exclusive lock on the file descriptor 99 which refers to our LOCK_FILE. This operation is guaranteed by the linux kernel to be atomic. Secondly, if it fails to acquire the lock, it exits with return code 1. We do not need to worry about any clean up. flock will automatically release the lock when the script exits regardless of how it terminates. This solves our problem!\nWhat if I wanted to add a more informational message instead of exiting directly on failure to acquire lock? We can change the line flock -n 99 || exit 1 as follows:\nflock -n 99 RC=$? if [ \u0026#34;$RC\u0026#34; != 0 ]; then # Send message and exit echo \u0026#34;Already running script. Try again after sometime\u0026#34; exit 1 fi The flock man page has an example which you can use to add an exclusive lock to start of any shell script:\n[ \u0026#34;${FLOCKER}\u0026#34; != \u0026#34;$0\u0026#34; ] \u0026amp;\u0026amp; exec env FLOCKER=\u0026#34;$0\u0026#34; flock -en \u0026#34;$0\u0026#34; \u0026#34;$0\u0026#34; \u0026#34;$@\u0026#34; || : This boilerplate uses the script file itself as a lock. It works by setting an environment variable $FLOCKER to script file name and executing the script with its original parameters after acquiring the lock. On failure however, it does not print anything and silently exits.\n$0 here stands for name of the script. $@ stands for all arguments passed to the script when it was called.\nUse case for me My team uses a test machine where we deploy multiple branches of a code-base. We need to make sure that exactly one person is building the project at a particular time. The deploy script pulls the specified branch of code from git and builds the project, deploys the main service and starts ancillary services. The script takes sometime to execute. If someone tries to deploy another branch while a build is ongoing, both can fail.\nWith the above snippet, calling the script more than once shows the current branch being built and exits with failure.\nFurther reading Flock man page Pitfalls of creating a lock file like in our initial snippet ","permalink":"https://rrampage.github.io/2018/11/06/ensuring-that-a-shell-script-runs-exactly-once/","summary":"Many times, we have shell scripts which perform some important stuff like inserting into database, mailing reports, etc which we want to run exactly one instance of.\nEnter locks! A simple solution is to create a \u0026ldquo;lock file\u0026rdquo; and check if the file exists when the script starts. If the file is already created, it means another instance of that program is running, so we can fail with message \u0026ldquo;Try again later!\u0026rdquo;. Once the script completes running, it will clean-up and delete the lock file.\nLOCK_FILE=a.lock if [ -f \u0026#34;$LOCK_FILE\u0026#34; ]; then # Lock file already exists, exit the script echo \u0026#34;An instance of this script is already running\u0026#34; exit 1 fi # Create the lock file echo \u0026#34;Locked\u0026#34; \u0026gt; \u0026#34;$LOCK_FILE\u0026#34; # Do the normal stuff # clean-up before exit rm \u0026#34;$LOCK_FILE\u0026#34; This looks promising but there are issues with this approach. What happens if the script does not end correctly i.e it exits because of some failure before it reaches the clean-up part of the code?","title":"Ensuring that a shell script runs exactly once"},{"content":"When your Linux machine runs out of memory, Out of Memory (OOM) killer is called by kernel to free some memory. It is often encountered on servers which have a number of memory intensive processes running. In this post, we dig a little deeper into when does OOM killer get called, how it decides which process to kill and if we can prevent it from killing important processes like databases.\nHow does OOM Killer choose which process to kill? The Linux kernel gives a score to each running process called oom_score which shows how likely it is to be terminated in case of low available memory. The score is proportional to the amount of memory used by the process. The score is 10 x percent of memory used by process. So the maximum score is 100% x 10 = 1000. In addition, if a process is running as a privileged user, it gets a slightly lower oom_score as compared to same memory usage by a normal user process. In earlier versions of Linux ( v2.6.32 kernel), there was a more elaborate heuristic which calculated this score.\nThe oom_score of a process can be found in the /proc directory. Let\u0026rsquo;s say that the process id (pid) of your process is 42, cat /proc/42/oom_score will give you the process\u0026rsquo; score.\nCan I ensure some important processes do not get killed by OOM Killer? Yes! The OOM killer checks oom_score_adj to adjust its final calculated score. This file is present in /proc/$pid/oom_score_adj. You can add a large negative score to this file to ensure that your process gets a lower chance of being picked and terminated by OOM killer. The oom_score_adj can vary from -1000 to 1000. If you assign -1000 to it, it can use 100% memory and still avoid getting terminated by OOM killer. On the other hand, if you assign 1000 to it, the Linux kernel will keep killing the process even when it uses minimal memory.\nLet\u0026rsquo;s go back to our process with pid 42. Here is how you can change its oom_score_adj:\necho -200 | sudo tee - /proc/42/oom_score_adj We need to do this as root user or sudo because Linux does not allow normal users to reduce the OOM score. You can increase the OOM score as a normal user without any special permissions. e.g echo 100 \u0026gt; /proc/42/oom_score_adj\nThere is also another, less fine-grained score called oom_adj which varies from -16 to 15. It is similar to oom_score_adj. In fact, when you set oom_score_adj, the kernel automatically scales it down and calculates oom_adj. oom_adj has a magic value of -17 which indicates that the given process should never be killed by OOM killer.\nDisplay OOM scores of all running processes This script displays the OOM score and OOM adjusted score of all running processes, in descending order of OOM score\n#!/bin/bash # Displays running processes in descending order of OOM score printf \u0026#39;PID\\tOOM Score\\tOOM Adj\\tCommand\\n\u0026#39; while read -r pid comm; do [ -f /proc/$pid/oom_score ] \u0026amp;\u0026amp; [ $(cat /proc/$pid/oom_score) != 0 ] \u0026amp;\u0026amp; printf \u0026#39;%d\\t%d\\t\\t%d\\t%s\\n\u0026#39; \u0026#34;$pid\u0026#34; \u0026#34;$(cat /proc/$pid/oom_score)\u0026#34; \u0026#34;$(cat /proc/$pid/oom_score_adj)\u0026#34; \u0026#34;$comm\u0026#34;; done \u0026lt; \u0026lt;(ps -e -o pid= -o comm=) | sort -k 2nr Check if any of your processes have been OOM-killed The easiest way is to grep your system logs. In Ubuntu: grep -i kill /var/log/syslog. If a process has been killed, you may get results like my_process invoked oom-killer: gfp_mask=0x201da, order=0, oom_score_adj=0\nCaveats of adjusting OOM scores Remember that OOM is a symptom of a bigger problem - low available memory. The best way to solve it is by either increasing the available memory (e.g better hardware) or moving some programs to other machines or by reducing memory consumption of programs (e.g allocate less memory where possible).\nToo much tweaking of the OOM adjusted score will result in random processes getting killed and not being able to free enough memory.\nReferences proc man page https://askubuntu.com/questions/60672/how-do-i-use-oom-score-adj/ Walkthrough on which part of Linux code is called Classic LWN article (a bit dated) Invoking the OOM killer manually ","permalink":"https://rrampage.github.io/2018/10/04/surviving-the-linux-oom-killer/","summary":"When your Linux machine runs out of memory, Out of Memory (OOM) killer is called by kernel to free some memory. It is often encountered on servers which have a number of memory intensive processes running. In this post, we dig a little deeper into when does OOM killer get called, how it decides which process to kill and if we can prevent it from killing important processes like databases.\nHow does OOM Killer choose which process to kill? The Linux kernel gives a score to each running process called oom_score which shows how likely it is to be terminated in case of low available memory. The score is proportional to the amount of memory used by the process. The score is 10 x percent of memory used by process. So the maximum score is 100% x 10 = 1000. In addition, if a process is running as a privileged user, it gets a slightly lower oom_score as compared to same memory usage by a normal user process.","title":"Surviving the Linux OOM Killer"},{"content":"Gray binary code is a way of expressing binary numbers such that consecutive numbers differ in exactly 1 digit. For example, in our conventional binary system, the numbers are\n000 001 010 011 100 101 110 111 and so on In Gray, they are:\n000 001 011 010 110 111 101 100 and so on In first system, when we go from \u0026lsquo;001\u0026rsquo; to \u0026lsquo;010\u0026rsquo;, there are 2 changes namely the unit\u0026rsquo;s place becomes \u0026lsquo;0\u0026rsquo; from \u0026lsquo;1\u0026rsquo; and the next digit becomes \u0026lsquo;1\u0026rsquo; from \u0026lsquo;0\u0026rsquo;. But in Gray\u0026rsquo;s system, \u0026lsquo;001\u0026rsquo; becomes \u0026lsquo;011\u0026rsquo; where there is only 1 change (that of 2nd digit).\nGray codes are used in error correction in communication.\nGenerating Gray codes of length n Is there a property we can use for easily generating the Gray codes of a given length? Yes! In our previous example, we generated all the Gray codes for n=3. Ignoring the most significant bit (MSB), notice how the 4th and 5th numbers are equal in their first 2 digits, as are the 3rd and 6th, 2nd and 7th and 1st and 8th. The last 4 numbers are reflection of the first 4 if we ignore the last digit. But the last digit is 0 for the 1st 4 numbers and 1 for the last 4\u0026hellip; We have a recursive formulation.\nR(0) = [] R(n+1) = 0R(n) + 1R\u0026rsquo;(n) (R\u0026rsquo;(n) = reverse of R(n)) For n=0, we have an empty list. For n+1, we take R(n), prepend 0 to all elements and to this sequence, we add reverse of R(n) prepended with 1.\nThis can be succinctly expressed in Python as:\ndef gray_code(n): if n \u0026lt;= 0: return [] if n == 1: return [\u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;] res = gray_code(n-1) return [\u0026#39;0\u0026#39;+s for s in res] + [\u0026#39;1\u0026#39;+s for s in res[::-1]] The above function returns in correct order all the 2^n Gray codes of length n. We had to add a case for n==1 because we are treating the numbers as strings so we can prepend \u0026lsquo;0\u0026rsquo; or \u0026lsquo;1\u0026rsquo;. As n=0 is an empty list, we need another case where we first add the strings.\nConverting a binary number to Gray code How do we convert a binary number to Gray code e.g what is Gray code equivalent of 7 (111 in binary)? From our earlier example, it is 100 = 4. So we need a function which takes an integer and returns the equivalent Gray code as integer.\nWe can use our recursive formulation from earlier to arrive at an algorithm. Let n = 2^a + b. Here, a is the MSB of n. G(n) is the Gray code of n. From our earlier formula, G(n) = 2^a + G(2^a-1-b) .. because of the reflection property. Thus, we know the value of G(n) at ath digit. We can keep iterating to get the other digits of G(n).\nOur pseudo-code:\ndef bin_to_gray(n): if n == 0: return 0 if n == 1: return 1 a = MSB(n) # Assume MSB function exists. It finds most significant bit of n b = n - 2**a return 2**a + bin_to_gray(2**a-1-b) from math import log2 as l2 # A simple way to find MSB def MSB(n): return int(l2(n)) An even faster way: It turns out that there is an even faster way of getting the nth Gray code from n. G(n) = n xor n/2\nIn C, Java or Python, this is expressed as:\nreturn n ^ (n \u0026gt;\u0026gt; 1) Addendum : Generating all Gray codes Knuth style! The legendary Donald Knuth uses this algorithm to generate all the tuples in his Art of Computer Programming Vol 4A:\npublic static void gen_gray_bin_taocp(int n) { boolean p = false; // parity bit byte[] a = new byte[n]; // each bit is an element in this array int j = 0; while (true) { System.out.println(Arrays.toString(a)); // Will print the number in reverse order p = !p; if (p) j = 0; else { j = 1; // Find min j so that a[j-1] = 1 while (j \u0026lt; n) { if (a[j-1] == 1) break; j++; if (j == n) // Termination condition return; } a[j] = (byte) (1-a[j]); // We flip the element at j } } ","permalink":"https://rrampage.github.io/2018/08/18/algorithms-gray-binary-code/","summary":"Gray binary code is a way of expressing binary numbers such that consecutive numbers differ in exactly 1 digit. For example, in our conventional binary system, the numbers are\n000 001 010 011 100 101 110 111 and so on In Gray, they are:\n000 001 011 010 110 111 101 100 and so on In first system, when we go from \u0026lsquo;001\u0026rsquo; to \u0026lsquo;010\u0026rsquo;, there are 2 changes namely the unit\u0026rsquo;s place becomes \u0026lsquo;0\u0026rsquo; from \u0026lsquo;1\u0026rsquo; and the next digit becomes \u0026lsquo;1\u0026rsquo; from \u0026lsquo;0\u0026rsquo;. But in Gray\u0026rsquo;s system, \u0026lsquo;001\u0026rsquo; becomes \u0026lsquo;011\u0026rsquo; where there is only 1 change (that of 2nd digit).\nGray codes are used in error correction in communication.\nGenerating Gray codes of length n Is there a property we can use for easily generating the Gray codes of a given length? Yes! In our previous example, we generated all the Gray codes for n=3. Ignoring the most significant bit (MSB), notice how the 4th and 5th numbers are equal in their first 2 digits, as are the 3rd and 6th, 2nd and 7th and 1st and 8th.","title":"Algorithms: Gray Binary Code"},{"content":"I have started the 100 days of code challenge. I intend to use this time to check out new languages and frameworks and solve some fun problems.\nI will update this post with my logs.\nAug 13 2018 D0 : Algorithms for calculating number of combinations and generating them in a lexicographical increasing order. Blog\nAug 14 2018 D1 : Working on algorithm for generating all permutations. First I managed to generate all possible r repetitions of n i.e n^r. Next, I read up and wrote code on Heap\u0026rsquo;s algorithm. I am still not sure of the intuition behind the algorithm. Also, it does not generate the permutations in lexicographical increasing order.\nAug 15 2018 D2 : Learned and implemented an algorithm that generates all permutations in a lexicographical order. It is not as efficient as Heap\u0026rsquo;s algorithm.\nAug 16 2018 D3 : Stumbled across the game of Set. Wrote a small python script which generates all solutions of any given game.\nAug 17 2018 D4 : Learning to use Puppeteer.js along with Google Cloud Functions. This dev.to post was very useful in getting me started.\nAug 18 2018 D5 : Read about Gray Codes, an alternative way of ordering binary numbers in TAOCP Vol 4. Wrote a blog post exploring some of their properties and how to generate them.\nAug 19 2018 D6 : Wrote a script which calculates iterations for Conway\u0026rsquo;s Game of Life\nAug 20 2018 D7 : Went through some Dynamic programming problems. Staircase problem is a good example of DP.\nAug 21 2018 D8: More recursion and DP. Towers of Hanoi and Longest unique sub-string problem.\nAug 24 2018 D9: After 2 days break due to travel, got back to C and linked lists. I am working through Stanford\u0026rsquo;s Linked List problems.\nAug 25 2018 D10 Working on a Sudoku solver. Made some more progress on the linked list problems from yesterday.\nAug 26 2018 D11 My sudoku solver can solve easy sudokus from Code Wars\nGist\nAug 27 2018 D12 Reading up on back-tracking and n-queens problem.\nAug 28 2018 D13 Some fun with numpy and pandas and setting up virtualenvs.\nAug 29 2018 D14 Solved Run Length Encoding problem recursively\nAug 30 2018 D15 Data visualization using matplotlib in Python\nAug 31 2018 D16 1D Cellular Automata in Java\nSep 1 2018 D17 Solved some regex golf problems\nSep 2 2018 D18 Played around with TMDB API using Python\nSep 3 2018 D19 Some interactive graph visualizations using Gephi\nSep 4 2018 D20 Implemented Tries in Java\nSep 5 2018 D21 Codewars kata on displaying a Tic-tac-toe board in C\nSep 6 2018 D22 Dynamic programming - Coin change problem!\nSep 7 2018 D23 Data cleaning using OpenRefine\nSep 8 2018 D24 Using SQLite for importing tabular data\nSep 9 2018 D25 SQLite window functions\nSep 13 2018 D26 After 3 day break because of job interviews and travel, a simple Python problem on moving 0s to the end of list on Codewars\nSep 14 2018 D27 Full-text search using SQLite (FTS4 and FTS5 engines)\nSep 15 2018 D28 n-Queens in Python using backtracking in just 20 lines! Code here: gist\nSep 16 2018 D29 Playing around with D3.js for data visualization\nSep 17 2018 D30 Creating SVGs of various shapes in HTML. Awesome guide here\nSep 18 2018 D31 Befunge interpreter on Codewars\nSep 19 2018 D32 Learned more about JS Array.reduce\nSep 20 2018 D33 Learned more about git branching and detaching from HEAD commit\nSep 21 2018 D34 Learned to use sed effectively\nSep 22 2018 D35 os.walk in Python is very nifty for crawling the filesystem!\nSep 23 2018 D36 More d3.js, visualizations using choropleths for maps\nSep 24 2018 D37 Learned how OOM killer works on Linux. Wrote an article here\nHave started working once again. I am putting this on hiatus till I find more time. Meanwhile, I will continue posting blog posts on my learning.\n","permalink":"https://rrampage.github.io/2018/08/13/100-days-of-code/","summary":"I have started the 100 days of code challenge. I intend to use this time to check out new languages and frameworks and solve some fun problems.\nI will update this post with my logs.\nAug 13 2018 D0 : Algorithms for calculating number of combinations and generating them in a lexicographical increasing order. Blog\nAug 14 2018 D1 : Working on algorithm for generating all permutations. First I managed to generate all possible r repetitions of n i.e n^r. Next, I read up and wrote code on Heap\u0026rsquo;s algorithm. I am still not sure of the intuition behind the algorithm. Also, it does not generate the permutations in lexicographical increasing order.\nAug 15 2018 D2 : Learned and implemented an algorithm that generates all permutations in a lexicographical order. It is not as efficient as Heap\u0026rsquo;s algorithm.\nAug 16 2018 D3 : Stumbled across the game of Set. Wrote a small python script which generates all solutions of any given game.","title":"100 Days Of Code"},{"content":"In how many different ways can we select r objects from a collection of n objects? In mathematics, this is called combinations.\nThe formula for the number of combinations is: where, n! denotes the factorial of a number that is the product of all numbers from 1 to n (inclusive).\nPrelude : A function for calculating factorial of a number public static long factorial(int n) { long res = 1L; for (int i = 1; i \u0026lt;= n; i++) { res *= i; } return res; } Calculating Combinations That was simple! Let us now move on to calculating the number of combinations given n and r\npublic static long combinations(int n, int r) { if (r \u0026lt; 0) { return 0; } long res = 1L; if (r \u0026gt; n - r) { r = n - r; } for (int i = 0; i \u0026lt; r; i++) { res *= (n - i); res /= (i + 1); } return res; } What does this algorithm do? Recall that we need to find n!/r!(n-r)! which will be of the form n(n-1)...(n-r+1)/1.2...r. Similar to factorial, we initialize the result as 1 and multiply by n-i and divide by i+1. Will this result in a fractional number? No. This is because first, we multiply by n and divide by 1. Next, we multiply by n-1 and divide by 2. Now, either n or n-1 have to be even (as they are consecutive numbers). Similarly, next when we divide by 3, one of n,n-1 and n-2 must be divisible by 3.\nIn the above code, we also make use of the mathematical property that combinations(n,r) = combinations(n,n-r). This way, we can do less number of operations for calculating the combinations.\nGenerating the combinations Counting the number of combinations was not so hard! Now, let\u0026rsquo;s generate all the combinations.\nGiven n and r, we will print out all the combinations. For the n objects, we will use the numbers from 0 to (n-1). Additionally, we will generate them in a lexicographical order which is math speak for sorted order. Finally, in a combination containing a and b, if a \u0026lt; b, we will print a b instead of b a. Formally stated, if a[k] and a[k+1] are the kth and (k+1)th elements in a generated combination, a[k] \u0026lt; a[k+1] for all k For example, given n = 4, r = 2, we have:\n0 1 0 2 0 3 1 2 1 3 2 3 i.e 6 combinations.\nNotice that we have 0 1 and not 1 0. This is because we are generating each combination in lexicographical order and we take the minimum for each combination.\nGenerating for a specific value of r (r = 2) If we have a specific value of r say 2, the code will involve 2 for loops like:\nfor (int i = 0; i \u0026lt; n-1; i++) { for (int j = i+1; j \u0026lt; n; j++) { println(i + \u0026#34; \u0026#34; + j); } } In the code above, our first loop variable i goes from 0 to n-2 and the next variable j goes from i+1 to n-1. Why so? This is because we have a requirement for taking the lexicographical minimum combination, so i \u0026lt; j from our constraints.\nIf value of r is fixed, we can simply create r for loops. But it is not fixed\u0026hellip;\nGeneralizing! Now, let\u0026rsquo;s move on to the main goal - generate combinations of n numbers taken r at a time. This section will be a little verbose as I have outlined how I arrived at the correct code. If you are interested in just the algorithm, feel free to skip to the bottom of the article\nIf we notice our previous code for r = 2, our first combination is always 0 1 as i = 0, j = 1. Similarly, if r was 3, our first combination would be 0 1 2. There is a pattern!\nBy creating an array a of size r, we can generate the first combination as 0 1 2 .. r-1. We have the first combination ready. What about the rest? Somehow, if we increment elements in this array, we will generate the combinations\u0026hellip;\nAgain, looking at the r = 2 case, notice that the last combination is n-2 n-1. Similarly, for r = 3, it is n-3 n-2 n-1. Thus, for r elements, it will be n-r+1 n-r+2 .. n-1. There is one more insight - there is exactly one combination which starts with n-r+1. If our array\u0026rsquo;s first element reaches n-r+1, we are done!\nWe now have a termination condition for our function: a[0] == n-r+1\nThe code we have so far will look like:\nint n; // Given int r; // Given int[] a = new int[r]; // Initialize array of size r for (int i = 0; i \u0026lt; r; i++) { a[i] = i; // Initialize array with first combination } while (a[0] \u0026lt; n-r+1) { // Our termination condition // DO SOMETHING! } We have a while loop that checks for termination condition. For the loop to terminate, we need to steadily progress from our first combination to the last combination. As we are generating elements in lexicographical order, the last element of the array must be incremented first. Then the second from last element and so on.\nIn our earlier example of n = 4, r = 2, we had\n0 1 0 2 0 3 1 2 1 3 2 3 After 0 3, we get 1 2. This means once the r-1 element (last element) reaches its maximum, we increment r-2 element from 0 to 1 and also reset the value of r-1 element to a[r-2]+1 as it must always be at least 1 greater than the r-2 element (from our constraints). Moving to our pseudo-code, let\u0026rsquo;s add this to the while loop\nint i = r-1; // variable i keeps track of which element in array we are incrementing while (a[0] \u0026lt; n-r+1) { // Our termination condition if (i \u0026gt; 0 \u0026amp;\u0026amp; a[i] == n-r+1) { i = i-1; //If a[i] has reached the max allowable value, decrement i and move to next element in array } printArray(a); // pseudo-code to print out the combination a[i] = a[i]+1; // increment if (i \u0026lt; r-1) { a[i+1] = a[i]+1; // Reset `i+1` element as previous element + 1, according to our constraints i = i+1; // Once you have reset the i+1 element, it is no longer \u0026lt; n-r+i and hence, we can move it back to old value } } We have an index variable i which we use to check which is the element in the array to be incremented. In the first if in above code, we check if the a[i] has reached its maximum value of n-r+i. If yes, we decrement i as a[i] can no longer be incremented. Moving out of if, we then print the combination and increment a[i]. Now, if i is no longer r-1 i.e it is no longer last element of a, we must reset it to r-1 and also set the value of a[r-1] as a[r-2]+1. This works for r=2. Hooray! We have abstracted out the for loop in the earlier section into a while loop with a few conditionals.\nBut does this work for r \u0026gt; 2? No\u0026hellip; We need a minor change to make it work! Change the if statements inside the loop to while loops and we are done! In case of first loop, we need to find the maximum i which is less than n+r-i. For example n=5, r=3 we have:\n0 1 2 0 1 3 0 1 4 0 2 3 0 2 4 0 3 4 1 2 3 1 2 4 1 3 4 2 3 4 As we move from 0 3 4 to 1 2 3, both i = 2 (a[2] = 4) and i = 1 (a[1] = 3) are at their maximum. We need to move to i = 0. Similarly, the second if must be a while loop because once we have incremented the a[i] for minimum i, we need to reset the outer elements of array to maintain our constraints.\nOur final code: int[] a = new int[r]; // initialize first combination for (int i = 0; i \u0026lt; r; i++) { a[i] = i; } int i = r - 1; // Index to keep track of maximum unsaturated element in array // a[0] can only be n-r+1 exactly once - our termination condition! while (a[0] \u0026lt; n - r + 1) { // If outer elements are saturated, keep decrementing i till you find unsaturated element while (i \u0026gt; 0 \u0026amp;\u0026amp; a[i] == n - r + i) { i--; } printArray(a); // pseudo-code to print array as space separated numbers a[i]++; // Reset each outer element to prev element + 1 while (i \u0026lt; r - 1) { a[i + 1] = a[i] + 1; i++; } } Proof of termination Now that we have our algorithm, how can we show that it terminates? In each iteration of our outer while loop, we increment the element of the array with maximum index i which has not reached value n-r+i while maintaining our constraints. Due to the lexicographical ordering, our previous combination is always lesser than our currently generated combination. As there are only a finite number of combinations till we reach our \u0026ldquo;last\u0026rdquo; combination, we can say that our algorithm will terminate.\nMeta: I began my 100 days of code challenge today with this problem. I will create a separate post explaining my motivations and plans.\nRegarding this problem statement of generating combinations, I had some trouble initially moving from r=2 case to the general one. It took me some time to find the correct termination condition. I am happy that the final algorithm is relatively compact. I also want to do a proof of correctness for this algorithm later.\n","permalink":"https://rrampage.github.io/2018/08/12/algorithms-generating-combinations/","summary":"In how many different ways can we select r objects from a collection of n objects? In mathematics, this is called combinations.\nThe formula for the number of combinations is: where, n! denotes the factorial of a number that is the product of all numbers from 1 to n (inclusive).\nPrelude : A function for calculating factorial of a number public static long factorial(int n) { long res = 1L; for (int i = 1; i \u0026lt;= n; i++) { res *= i; } return res; } Calculating Combinations That was simple! Let us now move on to calculating the number of combinations given n and r\npublic static long combinations(int n, int r) { if (r \u0026lt; 0) { return 0; } long res = 1L; if (r \u0026gt; n - r) { r = n - r; } for (int i = 0; i \u0026lt; r; i++) { res *= (n - i); res /= (i + 1); } return res; } What does this algorithm do?","title":"Algorithms: Generating Combinations"},{"content":"Awk is a small but capable programming language which is used for processing text. It was developed by Aho, Weinberger, Kerninghan at Bell Labs.\nJulia Evans made an awesome Awk comic: Awk scans input file as a sequence of lines and splits each line into fields. The field separator is usually whitespace but you can customize it to any character.\nAn awk program is a sequence of pattern-action pairs i.e for each line, it checks if it matches the pattern and if yes, it performs the associated action on the line. Awk can be used interactively or to run saved programs.\nHere is what Awk does written in Python-like pseudocode:\ninitialize() # Initializes variables in BEGIN block for line in input_lines: # Awk divides file / input into a list of lines for condition, action in conditions: # A program is a list of condition-action pairs if condition(line): #match line against condition action() #perform action on match Here are some small snippets of Awk:\nExample - Hello World! You can run awk programs inline or through a file:\nawk \u0026#39;BEGIN{ print \u0026#34;Hello, World!\u0026#34;}\u0026#39; Alternatively, you can save this to a file hello.awk:\nBEGIN{ print \u0026#34;Hello, World!\u0026#34;} Then run it as awk -f hello.awk\nExample - Reading a CSV and printing a specific column Let\u0026rsquo;s now do something useful! Download this csv which is 2010 census data by zip code in Los Angeles city.\nRead the first 3 lines from csv: head -3 2010_Census_Populations_by_Zip_Code.csv\nZip Code,Total Population,Median Age,Total Males,Total Females,Total Households,Average Household Size 91371,1,73.5,0,1,1,1 90001,57110,26.6,28468,28642,12971,4.4 We will print just the total column using awk -F, '{print $2}' 2010_Census_Populations_by_Zip_Code.csv\nThe -F, sets the field separator to comma as we need to split by commas for getting fields in a CSV file. $n allows you to use the value in the nth column.\nExample - Computing some statistics Awk allows the use of variables and functions. Let\u0026rsquo;s see how to use them by computing the total population in the entire city.\n# total.awk {s += $2} END {print \u0026#34;Total population:\u0026#34;, s} Variables are by default initialized to 0. Here, we use a variable s to hold the total.\nRunning this script as awk -F, -f total.awk 2010_Census_Populations_by_Zip_Code.csv, we get output: Total population: 10603988\nSpecial variables and built-in functions Awk uses some special variables and functions to make your programs more compact:\nNF : Number of fields in a line NR : Line number $0 : The entire input line length : gives number of characters in a string Now, we will compute the average household size which is total population divided by total households. The columns of interest are $2 and $6. We also want the average population per zip code. Our script:\n# stats.awk { s += $2; h += $6;} END {print \u0026#34;Total population:\u0026#34;, s, \u0026#34;\\nTotal households:\u0026#34;, h, \u0026#34;\\nAverage household size:\u0026#34;, s/h, \u0026#34;\\nAverage population per zip code:\u0026#34;, s/NR} NR gives us the total number of lines. But we do not want the header line. We can use tail command to skip the 1st line as tail -n +2. Running tail -n +2 2010_Census_Populations_by_Zip_Code.csv | awk -F, -f total.awk gives us :\nTotal population: 10603988 Total households: 3497698 Average household size: 3.0317 Average population per zip code: 33241.3 Example - Pattern matching We have done some useful things with awk so far, but we have ignored its biggest strength - pattern matching. We can match based on field values, regexes, line numbers.\nPrint every 2nd line : NR%2 == 0 {print $0}. Here $0 stands for the entire line. Print all zip codes with population \u0026gt; 100,000 : $2 \u0026gt; 100000 {print $1} Print all zip codes with population \u0026gt; 10,000 and average household size \u0026gt; 4 : $2 \u0026gt; 10000 \u0026amp;\u0026amp; $7 \u0026gt; 4 { print $1}. We can combine conditions using \u0026amp;\u0026amp; and || which stand for logical and and or respectively. Further reading There is a lot more to Awk. Here are some references:\nThe best resource for learning Awk is The AWK programming language written by the same trio. This book goes over and beyond a typical programming language tutorial and teaches you how to use your Awk superpowers to build versatile systems like a relational database, a parser, an interpreter, etc.\nThe GNU Awk Manual for Effective Awk Programming is a thorough reference.\n","permalink":"https://rrampage.github.io/2018/05/26/awk-a-useful-little-language/","summary":"Awk is a small but capable programming language which is used for processing text. It was developed by Aho, Weinberger, Kerninghan at Bell Labs.\nJulia Evans made an awesome Awk comic: Awk scans input file as a sequence of lines and splits each line into fields. The field separator is usually whitespace but you can customize it to any character.\nAn awk program is a sequence of pattern-action pairs i.e for each line, it checks if it matches the pattern and if yes, it performs the associated action on the line. Awk can be used interactively or to run saved programs.\nHere is what Awk does written in Python-like pseudocode:\ninitialize() # Initializes variables in BEGIN block for line in input_lines: # Awk divides file / input into a list of lines for condition, action in conditions: # A program is a list of condition-action pairs if condition(line): #match line against condition action() #perform action on match Here are some small snippets of Awk:","title":"Awk - A useful little language"},{"content":"This is part 2 of my series on JVM Memory management and debugging. Read part 1 here\nIn this post, we will cover symptoms of memory issues for JVM-based applications, which tools we can use to diagnose them and how we can fix them.\nSymptoms Here are a few symptoms of memory issues:\nPoor application performance Abnormal memory usage OutOfMemory errors (OOME) Poor Application Performance Application not performing to expected level Long response times Dropping client requests Stuck threads Service unavailability Large gaps in timestamps in application logs Causes of memory problems: Misconfigured memory Old generation memory space is sized smaller than live-set of objects. This triggers a major garbage collection (GC), resulting in larger pauses. Code cache is smaller than generated compiled code footprint Young generation is not sized appropriately leading to premature promotion of objects PermGen / Metaspace not sized correctly leading to full GC Memory leaks - Unintentional retention of objects in memory spaces Unintentional references to set of objects in heap Not dereferencing classloader instances appropriateky Not releasing native resources appropriately Excessive use of finalizers Objects with finalizers may delay their own GC Finalizer thread needs to invoke finalize() method of the instances before reclaiming them There can only be 1 Finalizer thread. If it does not keep up with rate at which objects become available for finalization, JVM fails with OOME Pending finalizer objects are essentially accumulated garbage Finalizers deprecated in Java 9 Explicit GC calls System.gc() and diagnostic data collections can cause long pauses -XX:+DisableExplicitGC can disable System.gc() calls -XX:+PrintClassHistogram also calls an explicit GC when receiving kill -3 signal OutOfMemoryError Hierarchy : Throwable -\u0026gt; Error -\u0026gt; VirtualMachineError -\u0026gt; OutOfMemoryError (Unchecked exception) Thrown when JVM runs out of space in various memory spaces or cannot proceed further with process execution. Some of the possibilities: Heap space full JVM already invoked full GC but could not free up space Heap may be sized smaller than app footprint or app is unnecessarily holding on to some set of objects in heap GC overhead limit exceeded Too many GCs with very less space claimed Application threads not getting any CPU cycles Requested array size exceeds VM limit PermGen space / Metaspace / compressed class space Full GC invoked but unable to free space in Metaspace and application is attempting to load more classes Metaspace by default \u0026ldquo;unlimited\u0026rdquo; but can be controlled by MaxMetaspaceSize. By default, 1 GB reserved for compressed class space Make sure that -Xnoclassgc is not in use as it prevents unloading of classes Native memory - out of swap space / stack trace with native method Native space used for Java thread stacks, loaded jars, zips, native libraries, native resources like files; mem allocated from native code Unable to allocate more native memory or to create new threads or native memory leaks Running 32 bit JVM on 64 bit machine puts 4 GB limit on process size Position of Java heap can put a cap on max size of native heap. Can be controlled by option -XX:HeapBaseMinAddress=n to specify address native heap should be based at CodeCache warnings warning message printed by JVM saying CodeCache full, compiler has been disabled. No OOME when code cache is full Emergency cleanup undertaken by Sweeper. This may discard compiled code and JIT may need to perform optimizations again Ensure appropriate size of CC using ReservedCodeCacheSize option Direct Buffer Memory ByteBuffer.allocateDirect(N) : Direct buffers which are garbage collected using phantom references and a reference queue Unlimited memory by default but can be controlled by -XX:MaxDirectMemorySize=n Used by Java NIO. Heap ByteBuffer for I/O uses temporary direct ByteBuffer Diagnostic Data, Data Collection and Analysis Tools Troubleshooting Memory leaks Confirm memory leak\nMonitor heap usage over time If full GCs unable to claim space in OldGen, could be config issue Heap size may be too small -\u0026gt; Increase heap size and monitor! If issue persists, it could be a memory leak -XX:+GCTimeLimit sets upper limit on amount of time GCs can spend in percent of total time, default 98% -XX:+GCHeapFreeLimit sets lower limit on amount of space that should be freed by a GC, represented as % of max heap, default is 2% OutOfMemoryError is thrown after a full GC if previous 5 consecutive GCs were not able to keep the GC cost below GCTimeLimit or free up at least GCHeapFreeLimit space PermGen/Metaspace may be too small if frequent Full GCs do not claim any space Diagnostic data and analysis\nGC logs are helpful for determining heap requirements, finding out excessive GCs and long GC pauses and in configuration of memory spaces For Java 9+, G1 options are: -Xlog:gc*,gc+phases=debug:file=gc.log . For non G1, -Xlog:gc*:file=gc.log. For older JVMs, -XX:+PrintGCDetails, -XX:+PrintGCTimeStamps, -XX:+PrintGCDateStamps, -Xloggc:gc.log For checking metaspace, -verbose:class or -XX:+TraceClassLoading , -XX:+TraceClassUnloading We can analyse logs through manual inspection, GCViewer, GCHisto, gceasy.io Heap dumps help determine unexpected memory growth and memory leaks. We can take heap dumps in follwing ways: jcmd pid GC.heap_dump heapdump.dmp jmap -dump:format=b,file=snapshot.jmap pid JConsole or Java Mission Control using MBean HotSpotDiagnostic JVM option heap dump on OOM error : -XX:+HeapDumpOnOutOfMemoryError . Frequent full GCs can delay collection of heap dump and restart of the process Eclipse Memory Analyzer Tool (MAT) shows leak suspects, histograms, unreachable objects, duplicate classes, reference chains to GC roots, allows using OQL to explore heap dumps. JOverFlow for JMC and Java VisualVM, YourKit (a commercial profiler) can all take heap dumps. Heap histograms - quick view of objects in heap Collect using: -XX:+PrintClassHistogram and SIGQUIT on Posix and SIGBREAK on Windows jcmd pid GC.class_histogram filename=histo jmap -histo pid core_file jhsdb jmap (Java 9) Java flight recordings - unexpected memory growth and memory leaks, GC events Enable Heap Statistics. Can introduce additional performance overhead To create a flight recording : -XX:+UnlockCommercialFeatures -XX:+FlightRecorder -XX:StartFlightRecording=delay=20s,duration=60s,name=Rec,filename=lol.jfr,settings=profile Flight recordings can find out type of leaking objects but you need heap dumps to find out what is causing the objects to leak Finalizers Collect data using JConsole, jmap Analyse using Eclipse MAT / Visual VM using heap dumps Native Memory Native Memory Tracker output - tracks native memory used internally by JVM, not for external libraries. Start JVM with NativeMemoryTracking option pmap, libumem, valgrind, core files Conclusion In this series, we have taken a look at how the JVM manages memory and how the garbage collection process works. We have also gone through how to diagnose memory issues, which tools to use to collect and analyze diagnostic information and some JVM options which can affect application performance.\n","permalink":"https://rrampage.github.io/2018/05/16/jvm-primer-part-2-debugging-memory-issues/","summary":"This is part 2 of my series on JVM Memory management and debugging. Read part 1 here\nIn this post, we will cover symptoms of memory issues for JVM-based applications, which tools we can use to diagnose them and how we can fix them.\nSymptoms Here are a few symptoms of memory issues:\nPoor application performance Abnormal memory usage OutOfMemory errors (OOME) Poor Application Performance Application not performing to expected level Long response times Dropping client requests Stuck threads Service unavailability Large gaps in timestamps in application logs Causes of memory problems: Misconfigured memory Old generation memory space is sized smaller than live-set of objects. This triggers a major garbage collection (GC), resulting in larger pauses. Code cache is smaller than generated compiled code footprint Young generation is not sized appropriately leading to premature promotion of objects PermGen / Metaspace not sized correctly leading to full GC Memory leaks - Unintentional retention of objects in memory spaces Unintentional references to set of objects in heap Not dereferencing classloader instances appropriateky Not releasing native resources appropriately Excessive use of finalizers Objects with finalizers may delay their own GC Finalizer thread needs to invoke finalize() method of the instances before reclaiming them There can only be 1 Finalizer thread.","title":"JVM Primer Part 2 - Debugging memory issues"},{"content":"This series is a summary of Oracle\u0026rsquo;s JVM troubleshooting course which gives an overview on JVM memory management, Hotspot VM\u0026rsquo;s garbage collection options, various memory errors and how to troubleshoot them.\nIn this post (part 1), we will have a look at how JVM manages memory and its different garbage collectors.\nYou can find Part 2 here\nJVM Memory Management Overview The JVM provides automatic memory management to free the programmer from manually managing memory. New objects are allocated on heap memory. A root set consists of pointers to external memory, static variables, threads, JNI references and internal JVM structures. Objects directly reachable from the root set must be kept in heap. Objects reachable from any of the reachable objects must also be in heap. This group of objects are the only ones which can be used by a program. The unreachable objects (garbage) are removed using a process called garbage collection (GC). Reachable objects are compacted i.e moved to contiguous space in heap. This is important as otherwise, the heap will become fragmented.\nGenerational GC and Memory Spaces in Hotspot When the JVM starts, it requests some memory from the OS. This memory is divided into various spaces.\nMemory spaces in JVM prior to JDK 8\nSeparate pools hold objects of diff age ranges JVM\u0026rsquo;s GC is generational and is based on the hypothesis that: Most objects die young Few references from older to younger objects There are 2 generations of objects: young : small and collected frequently (minor collection). Objects which survive a threshold number of GCs move to old generation. old : large, collected infrequently (major collection = Full GC) Prior to JDK 8, there was also a permanent generation which was for storing class representations and metadata, interned strings and class statics. This was replaced by meta-space in JDK 8 and later. Meta-space is allocated in native memory. It is managed through JVM options MetaspaceSize for initial size and MaxMetaspaceSize for maximum. If UseCompressedClassPointers is enabled, 2 areas of memory are used for storing classes and their metadata - meta-space and compressed class space. 64 bit class pointers represented with 32 bit offsets to save space. Class metadata is referenced by 32 bit offsets stored in compressed class space. By default, compressed class space is 1 GB. Code cache is used to store compiled code generated by JIT (Just in time optimizer), allocated out of native memory and managed by Code Cache Sweeper Garbage Collectors in Hotspot JVM The JVM has different garbage collection methods for different generations of objects. Some of them are described below:\nYoung generation collection Serial - Stop-the-world (STW), copying collector, single threaded ParNew - STW, copying collector, multiple GC threads Parallel Scavenge - STW, copying collector, multiple GC threads Old generation collection Serial Old - STW, mark-sweep-compact collector, single threaded CMS - Mostly concurrent, low pause Parallel Old - compacting collector, multiple GC threads G1 : designed for large heaps and offers predictable short pauses. Has different memory layout for generations Same collector for all generations GC options for JDK These are the option flags passed to JVM for specifying which GC to use:\nUseSerialGC : Serial + SerialOld UseParNewGC : ParNew + SerialOld . In JDK 9, uses CMS for old gen UseConcMarkSweepGC : ParNew + CMS + SerialOld CMS used most of time to collect old generation. SerialOld used when concurrent mode failure occurs. CMS performs most work in concurrent with application threads. No heap compaction leads to fragmentation. Has floating garbage and requires larger heap sizes. Free space maintained as linked lists. Allocation expensive compared to bump-the-pointer allocations. Additional overhead on young collections Deprecated in JDK 9 UseParallelGC : Parallel Scavenge + Parallel Old. Maximizes throughput. Default GC till JDK 9 UseG1GC - G1 for both generations Server style GC for multi-core machines with large memory Low GC pauses with high probability while trying for high throughput Compacting collector. Low pauses without fragmentation Better GC ergonomics. Parallel threads and some tasks are concurrent with application threads Available since JDK 7u4 and default in JDK 9 For more detailed information on tuning the garbage collector, read the official GC Tuning Guide\nMinor GC or How young generation is collected: When Eden space in young gen is full, reachable objects are marked and moved to the ToSurvivorSpace Objects in FromSurvivor space that are reachable are moved to ToSurvivorSpace Objects in FromSurvivor space that have crossed the threshold are promoted to the old generation Eden becomes empty and is ready for new allocations To and From Survivor Spaces are switched Notes on Mark-Sweep-Compact collector (Serial Old): Mark phase : marks all live objects Sweep phase : sweeps over heap identifying garbage Slide phase : GC performs a sliding compaction by sliding live objects to the start of the heap ","permalink":"https://rrampage.github.io/2018/05/15/a-primer-on-jvm-memory-management-and-troubleshooting-1/","summary":"This series is a summary of Oracle\u0026rsquo;s JVM troubleshooting course which gives an overview on JVM memory management, Hotspot VM\u0026rsquo;s garbage collection options, various memory errors and how to troubleshoot them.\nIn this post (part 1), we will have a look at how JVM manages memory and its different garbage collectors.\nYou can find Part 2 here\nJVM Memory Management Overview The JVM provides automatic memory management to free the programmer from manually managing memory. New objects are allocated on heap memory. A root set consists of pointers to external memory, static variables, threads, JNI references and internal JVM structures. Objects directly reachable from the root set must be kept in heap. Objects reachable from any of the reachable objects must also be in heap. This group of objects are the only ones which can be used by a program. The unreachable objects (garbage) are removed using a process called garbage collection (GC). Reachable objects are compacted i.e moved to contiguous space in heap.","title":"A Primer on JVM Memory Management and Troubleshooting - 1"},{"content":"Snake case and Camel case are conventions of naming variables, functions and classes. Most teams and projects prescribe a particular case in their style guides.\nExamples of camel case:\nMyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher Examples of snake case:\nadd matrix_add diagonal_matrix_add pseudo_inverse If we want to convert back and forth between these cases, we must look for the points of interest - the word boundaries. Camel case boundaries have the first letter capitalized while the snake case word boundaries have an _.\nSnake case to camel case Here is a regular expression for finding out the _ and the first letter in the next word:\n(.*?)_([a-zA-Z]) This regex has 2 parts:\n(.*?) finds everything upto the _.\nThe \u0026lsquo;.\u0026rsquo; means any character. \u0026lsquo;*\u0026rsquo; stands for match 0 or more instances \u0026lsquo;?\u0026rsquo; stands for non-greedy match. We must use \u0026lsquo;?\u0026rsquo; in the pattern because the regex engine will try to match as much as possible by default. So, if we use just (.*), the whole word will be consumed and nothing will be left for the rest of the pattern. \u0026lsquo;()\u0026rsquo; stand for a group. A group is a way of saving a part of the match for later. Together, they mean that find all characters upto the first \u0026lsquo;_\u0026rsquo; and capture them in a group. ([a-zA-Z]) finds the first alphabet after the _. We need this to convert to upper case for Camel case.\nThe Python code below converts words which are in snake case to camel case:\nimport re REG = r\u0026#34;(.*?)_([a-zA-Z])\u0026#34; def camel(match): return match.group(1) + match.group(2).upper() def camel_upper(match): return match.group(1)[0].upper() + match.group(1)[1:] + match.group(2).upper() words = \u0026#34;\u0026#34;\u0026#34;add matrix_add diagonal_matrix_add pseudo_inverse\u0026#34;\u0026#34;\u0026#34;.splitlines() results = [re.sub(REG, camel, w, 0) for w in words] print(results) # Output: # [\u0026#39;add\u0026#39;, \u0026#39;matrixAdd\u0026#39;, \u0026#39;diagonalMatrixAdd\u0026#39;, \u0026#39;pseudoInverse\u0026#39;] We use the regex we constructed earlier and the re.sub method to substitute our matched words. We pass a method called camel as an argument. This method allows us to change the case of the letter in the second group and keep the first group unchanged. Notice that the first letter can be either lower or upper depending on whether it is a variable or method (lower) or a class (upper). The camel_upper method can be used for class names.\nCamel case to snake case Similarly, for converting from camel to snake case, the regex is:\n(.+?)([A-Z]) And the Python code :\nimport re REG = r\u0026#34;(.+?)([A-Z])\u0026#34; def snake(match): return match.group(1).lower() + \u0026#34;_\u0026#34; + match.group(2).lower() words = \u0026#34;\u0026#34;\u0026#34;MyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher\u0026#34;\u0026#34;\u0026#34;.splitlines() results = [re.sub(REG, snake, w, 0) for w in words] print(results) # Output # [\u0026#39;my_class\u0026#39;, \u0026#39;my_class_factory\u0026#39;, \u0026#39;my_class_factory_builder\u0026#39;, \u0026#39;my_class_factory_builder_impl\u0026#39;, \u0026#39;my_instance\u0026#39;, \u0026#39;my_instance2\u0026#39;, \u0026#39;abc\u0026#39;, \u0026#39;pattern_matcher\u0026#39;] ","permalink":"https://rrampage.github.io/2018/05/09/snake-case-to-camel-case-and-back-using-regular-expressions-and-python/","summary":"Snake case and Camel case are conventions of naming variables, functions and classes. Most teams and projects prescribe a particular case in their style guides.\nExamples of camel case:\nMyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher Examples of snake case:\nadd matrix_add diagonal_matrix_add pseudo_inverse If we want to convert back and forth between these cases, we must look for the points of interest - the word boundaries. Camel case boundaries have the first letter capitalized while the snake case word boundaries have an _.\nSnake case to camel case Here is a regular expression for finding out the _ and the first letter in the next word:\n(.*?)_([a-zA-Z]) This regex has 2 parts:\n(.*?) finds everything upto the _.\nThe \u0026lsquo;.\u0026rsquo; means any character. \u0026lsquo;*\u0026rsquo; stands for match 0 or more instances \u0026lsquo;?\u0026rsquo; stands for non-greedy match. We must use \u0026lsquo;?\u0026rsquo; in the pattern because the regex engine will try to match as much as possible by default. So, if we use just (.","title":"Snake case to camel case and back using regular expressions and Python"},{"content":"Background Today, I resumed a rust project of mine after a long time. In order to check my last working code, I ran cargo run. But it refused to run with error message:\n....\u0026#34;-Wl,-Bdynamic\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;dl\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;gcc_s\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;c\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;m\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; = note: /usr/bin/ld: cannot find Scrt1.o: No such file or directory collect2: error: ld returned 1 exit status Linker Issues! ld is used to link libraries. So, the error was not in the code but in the linking phase. I googled the error and the solution was to have build-essential package installed. But the package was already installed on my machine (it is one of the first packages I install on any development machine).\nSome more googling revealed that cargo uses the system cc linker to link to the C runtime. Running which cc gave me $HOME/anaconda3/bin/cc. This cc is part of my Anaconda root environment. (Anaconda is a package manager for scientific computing packages. It is a convenient way for installing multiple versions of packages in different environments).\nOn Linux, the linker knows where to find the required libraries using the shared library cache. I ran ldconfig -v to refresh it and then try again. Same error!\nIt is possible to explicitly list directories to include using LD_LIBRARY_PATH environment variable. I tried setting the LD_LIBRARY_PATH to point to the required directory and then run cargo as LD_LIBRARY_PATH=DIR cargo build -v. But it gave the same error.\nI thought that cargo must be setting the linker value somewhere, so instead let me try directly compiling with rustc. Even that gave the same error. With this, I eliminated the possibility of some environment variable only affecting cargo.\nMore googling! Further searching for the error with \u0026ldquo;rust\u0026rdquo; added showed me results of people having trouble cross-compiling. From this, I learned that cargo has different targets i.e different instruction sets (e,g x86-64, arm, x86, mips), different OSs (e.g linux, windows, freebsd) and different C runtimes (e.g glibc, musl, msvc). The Rust documentation on cargo mentioned that this is called a target triple. The Cargo book mentioned that you can direct cargo to explicitly use a particular linker using RUSTFLAGS environment variable.\nSince I am only building for my machine, I had to find out the exact value of the target. Rust gives an exhaustive list of all supported targets by running rustc --print target-list. My target was x86_64-unknown-linux-gnu.\nIt is possible to pass a linker to cargo explicitly as RUSTFLAGS=\u0026quot;-C linker=x86_64-unknown-linux-gnu\u0026quot; cargo build -v. It worked!\nAll-time fix! I do not want to do this every time I run cargo. The Cargo book says that cargo uses a global config file in $HOME/.cargo/config.\nI added the following to the file:\n# Specify which linker to use for this target [target.x86_64-unknown-linux-gnu] linker = \u0026#34;x86_64-linux-gnu-gcc\u0026#34; Now, cargo build works without issues.\n","permalink":"https://rrampage.github.io/2018/05/09/cargo-refused-to-build-my-project-a-rust-debugging-story/","summary":"Background Today, I resumed a rust project of mine after a long time. In order to check my last working code, I ran cargo run. But it refused to run with error message:\n....\u0026#34;-Wl,-Bdynamic\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;dl\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;gcc_s\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;c\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;m\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; = note: /usr/bin/ld: cannot find Scrt1.o: No such file or directory collect2: error: ld returned 1 exit status Linker Issues! ld is used to link libraries. So, the error was not in the code but in the linking phase. I googled the error and the solution was to have build-essential package installed. But the package was already installed on my machine (it is one of the first packages I install on any development machine).\nSome more googling revealed that cargo uses the system cc linker to link to the C runtime. Running which cc gave me $HOME/anaconda3/bin/cc. This cc is part of my Anaconda root environment.","title":"Cargo refused to build my project - A Rust debugging story!"},{"content":"Many times, smoothly running processes stop working mysteriously. You open the logs and see what is happening, only to find that even the logs have stopped updating. But the process itself is running. You SSH to the server and type cd TAB. Bash weeps \u0026ldquo;Unable to create temporary file\u0026rdquo;. The machine is out of disk space\u0026hellip;\nHere is a checklist to make disk space debugging easier, using standard Linux utilities so you can get started without having to install anything extra:\ndf -h command gives you an overview in a readable format about the number of disks mounted and their total and available capacities. To get an idea of which folders/directories are eating up the maximum space, try out du -ch / | sort -h | tail -n 30. This gives you the 30 most space consuming directories. If you already know which directories generate maximum disk output e.g logs and temp files, you can replace the \u0026lsquo;/\u0026rsquo; with your directory (DIR) and run the command as du -ch DIR | sort -h | tail -n 30 Now that we have identified the directories with maximum space consumed, we may need to delete some files and get our process going again. The rm command is your friend here. You can delete old logs and temporary files to free up space. Many times, the culprit is a single large file which is already in use by a program e.g catalina.out by Apache Tomcat. If you want to free up space without shutting down the process, the truncate command will help you out. Example: truncate -s0 BIG_LOG.log. This will truncate the file to 0 bytes and still allow the other process to use it without issues (standard Unix permissions apply) Sometimes, you delete files and still, the space does not seem to be recovered. This can be because some process is still holding on to the file descriptor of the deleted file. Once these processes are stopped, the space will be recovered. The lsof command will help you out here. It stands for list open files. You can find out which processes are using deleted files as follows: lsof | grep deleted | grep OLD_FILENAME. The lsof command gives you the process name and the process id so you can run kill on the process. If you do not know the name of the deleted file, you can still run lsof | grep deleted and see the output to check for any familiar file / process. Finally, keep in mind that disk space is one of the metrics you should monitor on your server. This checklist must be used in a pinch. If you find yourself constantly having disk space issues, the solution is to set up periodic deletion/rotation of old log files, alerts when the disk space reaches a particular threshold or to increase the disk size if your processes require a lot of disk space e.g Kafka, MySQL and other databases.\nLet me know if there are some other tools I am missing out on and your experiences dealing with disk space issues!\n","permalink":"https://rrampage.github.io/2018/05/04/disk-space-debugging-checklist/","summary":"Many times, smoothly running processes stop working mysteriously. You open the logs and see what is happening, only to find that even the logs have stopped updating. But the process itself is running. You SSH to the server and type cd TAB. Bash weeps \u0026ldquo;Unable to create temporary file\u0026rdquo;. The machine is out of disk space\u0026hellip;\nHere is a checklist to make disk space debugging easier, using standard Linux utilities so you can get started without having to install anything extra:\ndf -h command gives you an overview in a readable format about the number of disks mounted and their total and available capacities. To get an idea of which folders/directories are eating up the maximum space, try out du -ch / | sort -h | tail -n 30. This gives you the 30 most space consuming directories. If you already know which directories generate maximum disk output e.g logs and temp files, you can replace the \u0026lsquo;/\u0026rsquo; with your directory (DIR) and run the command as du -ch DIR | sort -h | tail -n 30 Now that we have identified the directories with maximum space consumed, we may need to delete some files and get our process going again.","title":"Disk Space Debugging Checklist"},{"content":"Hello World!\n","permalink":"https://rrampage.github.io/2014/03/03/hello-world/","summary":"Hello World!","title":"Hello World"},{"content":"About this blog: the delights and frustrations of programming new things I learn/stumble across while coding interesting concepts/resources I come across trying to explain a few topics About Me I am a software developer. I work on mostly backend stuff. I blog occasionally here or crosspost to dev.to. You can reach out to me via various websites in the footer.\n Ask me about \u0026hellip; Bash, sed, awk, GNU Make, jq Linux Postgres/MySQL/SQLite Java/Kotlin, JOOQ, Dropwizard Solr \u0026amp; Elasticsearch ArangoDB Nginx \u0026amp; Openresty State machines, Regexes, State charts  How to reach me: Mastodon LinkedIn Twitter Software powering this blog: Hugo Theme - PaperMod Github pages ","permalink":"https://rrampage.github.io/about/","summary":"About this blog: the delights and frustrations of programming new things I learn/stumble across while coding interesting concepts/resources I come across trying to explain a few topics About Me I am a software developer. I work on mostly backend stuff. I blog occasionally here or crosspost to dev.to. You can reach out to me via various websites in the footer.\n Ask me about \u0026hellip; Bash, sed, awk, GNU Make, jq Linux Postgres/MySQL/SQLite Java/Kotlin, JOOQ, Dropwizard Solr \u0026amp; Elasticsearch ArangoDB Nginx \u0026amp; Openresty State machines, Regexes, State charts  How to reach me: Mastodon LinkedIn Twitter Software powering this blog: Hugo Theme - PaperMod Github pages ","title":"About"}]