[{"content":"Lua - Basics for x = 0, 10, 1 do print(x) end -- for loop with range and step. step if not given is assumed to be 1 -- Tables are the soul of Lua. They double up as arrays and hashes a = {} b = {1, 2, 3} b[1] -- b[1] will return 1 as indexing for arrays is from 1 c = {[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7}} -- We can have a \u0026#34;0\u0026#34;th index by adding the 1st element as [0]=value -- Adding keys which are not valid identifiers in Lua needs to be done by wrapping key in [] -- If a key is a valid identifier, we can access using `.` e.g c.a for above code vs c[0] for k,v in pairs(c) do print(type(k)) end -- iterates through k/v in table and prints type of key Print a table as valid Lua code function printTable(tbl) -- Specify function vars as local else they become global local s = \u0026#34;{\u0026#34; local fst = true for k,v in pairs(tbl) do local tk = type(k) local tv = type(v) if not fst then s = s .. \u0026#34;,\u0026#34; else fst = false end if tk == \u0026#34;number\u0026#34; or tk == \u0026#34;boolean\u0026#34; then s = s .. \u0026#34;[\u0026#34; .. tostring(k) .. \u0026#34;]=\u0026#34; else s = s .. \u0026#39;[\u0026#34;\u0026#39; .. k .. \u0026#39;\u0026#34;]=\u0026#39; end if tv == \u0026#34;table\u0026#34; then s = s .. printTable(v) elseif tv == \u0026#34;number\u0026#34; or tv == \u0026#34;boolean\u0026#34; then s = s .. tostring(v) elseif tv == \u0026#34;string\u0026#34; then s = s .. \u0026#39;\u0026#34;\u0026#39; .. v .. \u0026#39;\u0026#34;\u0026#39; else s = s .. vt end end s = s .. \u0026#34;}\u0026#34; return s end sv = printTable({[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7},[true]=123}) print(sv) -- posts.lua (saved table) can be read from another lua file as posts=require(\u0026#34;posts\u0026#34;) return {[0]={[1]=123,[2]=3},[\u0026#34;v\u0026#34;]={[1]=2,[2]=6,[3]=7},[\u0026#34;a\u0026#34;]={[1]=1,[2]=2,[3]=3},[true]=123} ","permalink":"https://rrampage.github.io/2021/12/04/relearning-lua/","summary":"Lua - Basics for x = 0, 10, 1 do print(x) end -- for loop with range and step. step if not given is assumed to be 1 -- Tables are the soul of Lua. They double up as arrays and hashes a = {} b = {1, 2, 3} b[1] -- b[1] will return 1 as indexing for arrays is from 1 c = {[0]={123,3},[\u0026#34;a\u0026#34;]={1,2,3},v={2,6,7}} -- We can have a \u0026#34;0\u0026#34;th index by adding the 1st element as [0]=value -- Adding keys which are not valid identifiers in Lua needs to be done by wrapping key in [] -- If a key is a valid identifier, we can access using `.` e.g c.a for above code vs c[0] for k,v in pairs(c) do print(type(k)) end -- iterates through k/v in table and prints type of key Print a table as valid Lua code function printTable(tbl) -- Specify function vars as local else they become global local s = \u0026#34;{\u0026#34; local fst = true for k,v in pairs(tbl) do local tk = type(k) local tv = type(v) if not fst then s = s .","title":"Re-learning Lua"},{"content":"Awk is a small but capable programming language which is used for processing text. It was developed by Aho, Weinberger, Kerninghan at Bell Labs.\nJulia Evans made an awesome awk comic: Awk scans input file as a sequence of lines and splits each line into fields. The field separator is usually whitespace but you can customize it to any character.\nAn awk program is a sequence of pattern-action pairs i.e for each line, it checks if it matches the pattern and if yes, it performs the associated action on the line. Awk can be used interactively or to run saved programs.\nHere is what Awk does written in Python-like pseudocode:\ninitialize() # Initializes variables in BEGIN block for line in input_lines: # Awk divides file / input into a list of lines for condition, action in conditions: # A program is a list of condition-action pairs if condition(line): #match line against condition action() #perform action on match Here are some small snippets of Awk:\nExample - Hello World! You can run awk programs inline or through a file:\nawk \u0026#39;BEGIN{ print \u0026#34;Hello, World!\u0026#34;}\u0026#39; Alternatively, you can save this to a file hello.awk:\nBEGIN{ print \u0026#34;Hello, World!\u0026#34;} Then run it as awk -f hello.awk\nExample - Reading a CSV and printing a specific column Let\u0026rsquo;s now do something useful! Download this csv which is 2010 census data by zip code in Los Angeles city.\nRead the first 3 lines from csv: head -3 2010_Census_Populations_by_Zip_Code.csv\nZip Code,Total Population,Median Age,Total Males,Total Females,Total Households,Average Household Size 91371,1,73.5,0,1,1,1 90001,57110,26.6,28468,28642,12971,4.4 We will print just the total column using awk -F, '{print $2}' 2010_Census_Populations_by_Zip_Code.csv\nThe -F, sets the field separator to comma as we need to split by commas for getting fields in a CSV file. $n allows you to use the value in the nth column.\nExample - Computing some statistics Awk allows the use of variables and functions. Let\u0026rsquo;s see how to use them by computing the total population in the entire city.\n# total.awk {s += $2} END {print \u0026#34;Total population:\u0026#34;, s} Variables are by default initialized to 0. Here, we use a variable s to hold the total.\nRunning this script as awk -F, -f total.awk 2010_Census_Populations_by_Zip_Code.csv, we get output: Total population: 10603988\nSpecial variables and built-in functions Awk uses some special variables and functions to make your programs more compact:\nNF : Number of fields in a line NR : Line number $0 : The entire input line length : gives number of characters in a string Now, we will compute the average household size which is total population divided by total households. The columns of interest are $2 and $6. We also want the average population per zip code. Our script:\n# stats.awk { s += $2; h += $6;} END {print \u0026#34;Total population:\u0026#34;, s, \u0026#34;\\nTotal households:\u0026#34;, h, \u0026#34;\\nAverage household size:\u0026#34;, s/h, \u0026#34;\\nAverage population per zip code:\u0026#34;, s/NR} NR gives us the total number of lines. But we do not want the header line. We can use tail command to skip the 1st line as tail -n +2. Running tail -n +2 2010_Census_Populations_by_Zip_Code.csv | awk -F, -f total.awk gives us :\nTotal population: 10603988 Total households: 3497698 Average household size: 3.0317 Average population per zip code: 33241.3 Example - Pattern matching We have done some useful things with awk so far, but we have ignored its biggest strength - pattern matching. We can match based on field values, regexes, line numbers.\nPrint every 2nd line : NR%2 == 0 {print $0}. Here $0 stands for the entire line. Print all zip codes with population \u0026gt; 100,000 : $2 \u0026gt; 100000 {print $1} Print all zip codes with population \u0026gt; 10,000 and average household size \u0026gt; 4 : $2 \u0026gt; 10000 \u0026amp;\u0026amp; $7 \u0026gt; 4 { print $1}. We can combine conditions using \u0026amp;\u0026amp; and || which stand for logical and and or respectively. Further reading There is a lot more to Awk. Here are some references:\nThe best resource for learning Awk is The AWK programming language written by the same trio. This book goes over and beyond a typical programming language tutorial and teaches you how to use your Awk superpowers to build versatile systems like a relational database, a parser, an interpreter, etc.\nThe GNU Awk Manual for Effective Awk Programming is a thorough reference.\n","permalink":"https://rrampage.github.io/2018/05/26/awk-a-useful-little-language/","summary":"Awk is a small but capable programming language which is used for processing text. It was developed by Aho, Weinberger, Kerninghan at Bell Labs.\nJulia Evans made an awesome awk comic: Awk scans input file as a sequence of lines and splits each line into fields. The field separator is usually whitespace but you can customize it to any character.\nAn awk program is a sequence of pattern-action pairs i.e for each line, it checks if it matches the pattern and if yes, it performs the associated action on the line. Awk can be used interactively or to run saved programs.\nHere is what Awk does written in Python-like pseudocode:\ninitialize() # Initializes variables in BEGIN block for line in input_lines: # Awk divides file / input into a list of lines for condition, action in conditions: # A program is a list of condition-action pairs if condition(line): #match line against condition action() #perform action on match Here are some small snippets of Awk:","title":"Awk - A useful little language"},{"content":"This is part 2 of my series on JVM Memory management and debugging. Read part 1 here\nIn this post, we will cover symptoms of memory issues for JVM-based applications, which tools we can use to diagnose them and how we can fix them.\nSymptoms Here are a few symptoms of memory issues:\nPoor application performance Abnormal memory usage OutOfMemory errors (OOME) Poor Application Performance Application not performing to expected level Long response times Dropping client requests Stuck threads Service unavailability Large gaps in timestamps in application logs Causes of memory problems: Misconfigured memory Old generation memory space is sized smaller than live-set of objects. This triggers a major garbage collection (GC), resulting in larger pauses. Code cache is smaller than generated compiled code footprint Young generation is not sized appropriately leading to premature promotion of objects PermGen / Metaspace not sized correctly leading to full GC Memory leaks - Unintentional retention of objects in memory spaces Unintentional references to set of objects in heap Not dereferencing classloader instances appropriateky Not releasing native resources appropriately Excessive use of finalizers Objects with finalizers may delay their own GC Finalizer thread needs to invoke finalize() method of the instances before reclaiming them There can only be 1 Finalizer thread. If it does not keep up with rate at which objects become available for finalization, JVM fails with OOME Pending finalizer objects are essentially accumulated garbage Finalizers deprecated in Java 9 Explicit GC calls System.gc() and diagnostic data collections can cause long pauses -XX:+DisableExplicitGC can disable System.gc() calls -XX:+PrintClassHistogram also calls an explicit GC when receiving kill -3 signal OutOfMemoryError Hierarchy : Throwable -\u0026gt; Error -\u0026gt; VirtualMachineError -\u0026gt; OutOfMemoryError (Unchecked exception) Thrown when JVM runs out of space in various memory spaces or cannot proceed further with process execution. Some of the possibilities: Heap space full JVM already invoked full GC but could not free up space Heap may be sized smaller than app footprint or app is unnecessarily holding on to some set of objects in heap GC overhead limit exceeded Too many GCs with very less space claimed Application threads not getting any CPU cycles Requested array size exceeds VM limit PermGen space / Metaspace / compressed class space Full GC invoked but unable to free space in Metaspace and application is attempting to load more classes Metaspace by default \u0026ldquo;unlimited\u0026rdquo; but can be controlled by MaxMetaspaceSize. By default, 1 GB reserved for compressed class space Make sure that -Xnoclassgc is not in use as it prevents unloading of classes Native memory - out of swap space / stack trace with native method Native space used for Java thread stacks, loaded jars, zips, native libraries, native resources like files; mem allocated from native code Unable to allocate more native memory or to create new threads or native memory leaks Running 32 bit JVM on 64 bit machine puts 4 GB limit on process size Position of Java heap can put a cap on max size of native heap. Can be controlled by option -XX:HeapBaseMinAddress=n to specify address native heap should be based at CodeCache warnings warning message printed by JVM saying CodeCache full, compiler has been disabled. No OOME when code cache is full Emergency cleanup undertaken by Sweeper. This may discard compiled code and JIT may need to perform optimizations again Ensure appropriate size of CC using ReservedCodeCacheSize option Direct Buffer Memory ByteBuffer.allocateDirect(N) : Direct buffers which are garbage collected using phantom references and a reference queue Unlimited memory by default but can be controlled by -XX:MaxDirectMemorySize=n Used by Java NIO. Heap ByteBuffer for I/O uses temporary direct ByteBuffer Diagnostic Data, Data Collection and Analysis Tools Troubleshooting Memory leaks Confirm memory leak\nMonitor heap usage over time If full GCs unable to claim space in OldGen, could be config issue Heap size may be too small -\u0026gt; Increase heap size and monitor! If issue persists, it could be a memory leak -XX:+GCTimeLimit sets upper limit on amount of time GCs can spend in percent of total time, default 98% -XX:+GCHeapFreeLimit sets lower limit on amount of space that should be freed by a GC, represented as % of max heap, default is 2% OutOfMemoryError is thrown after a full GC if previous 5 consecutive GCs were not able to keep the GC cost below GCTimeLimit or free up at least GCHeapFreeLimit space PermGen/Metaspace may be too small if frequent Full GCs do not claim any space Diagnostic data and analysis\nGC logs are helpful for determining heap requirements, finding out excessive GCs and long GC pauses and in configuration of memory spaces For Java 9+, G1 options are: -Xlog:gc*,gc+phases=debug:file=gc.log . For non G1, -Xlog:gc*:file=gc.log. For older JVMs, -XX:+PrintGCDetails, -XX:+PrintGCTimeStamps, -XX:+PrintGCDateStamps, -Xloggc:gc.log For checking metaspace, -verbose:class or -XX:+TraceClassLoading , -XX:+TraceClassUnloading We can analyse logs through manual inspection, GCViewer, GCHisto, gceasy.io Heap dumps help determine unexpected memory growth and memory leaks. We can take heap dumps in follwing ways: jcmd pid GC.heap_dump heapdump.dmp jmap -dump:format=b,file=snapshot.jmap pid JConsole or Java Mission Control using MBean HotSpotDiagnostic JVM option heap dump on OOM error : -XX:+HeapDumpOnOutOfMemoryError . Frequent full GCs can delay collection of heap dump and restart of the process Eclipse Memory Analyzer Tool (MAT) shows leak suspects, histograms, unreachable objects, duplicate classes, reference chains to GC roots, allows using OQL to explore heap dumps. JOverFlow for JMC and Java VisualVM, YourKit (a commercial profiler) can all take heap dumps. Heap histograms - quick view of objects in heap Collect using: -XX:+PrintClassHistogram and SIGQUIT on Posix and SIGBREAK on Windows jcmd pid GC.class_histogram filename=histo jmap -histo pid core_file jhsdb jmap (Java 9) Java flight recordings - unexpected memory growth and memory leaks, GC events Enable Heap Statistics. Can introduce additional performance overhead To create a flight recording : -XX:+UnlockCommercialFeatures -XX:+FlightRecorder -XX:StartFlightRecording=delay=20s,duration=60s,name=Rec,filename=lol.jfr,settings=profile Flight recordings can find out type of leaking objects but you need heap dumps to find out what is causing the objects to leak Finalizers Collect data using JConsole, jmap Analyse using Eclipse MAT / Visual VM using heap dumps Native Memory Native Memory Tracker output - tracks native memory used internally by JVM, not for external libraries. Start JVM with NativeMemoryTracking option pmap, libumem, valgrind, core files Conclusion In this series, we have taken a look at how the JVM manages memory and how the garbage collection process works. We have also gone through how to diagnose memory issues, which tools to use to collect and analyze diagnostic information and some JVM options which can affect application performance.\n","permalink":"https://rrampage.github.io/2018/05/16/jvm-primer-part-2-debugging-memory-issues/","summary":"This is part 2 of my series on JVM Memory management and debugging. Read part 1 here\nIn this post, we will cover symptoms of memory issues for JVM-based applications, which tools we can use to diagnose them and how we can fix them.\nSymptoms Here are a few symptoms of memory issues:\nPoor application performance Abnormal memory usage OutOfMemory errors (OOME) Poor Application Performance Application not performing to expected level Long response times Dropping client requests Stuck threads Service unavailability Large gaps in timestamps in application logs Causes of memory problems: Misconfigured memory Old generation memory space is sized smaller than live-set of objects. This triggers a major garbage collection (GC), resulting in larger pauses. Code cache is smaller than generated compiled code footprint Young generation is not sized appropriately leading to premature promotion of objects PermGen / Metaspace not sized correctly leading to full GC Memory leaks - Unintentional retention of objects in memory spaces Unintentional references to set of objects in heap Not dereferencing classloader instances appropriateky Not releasing native resources appropriately Excessive use of finalizers Objects with finalizers may delay their own GC Finalizer thread needs to invoke finalize() method of the instances before reclaiming them There can only be 1 Finalizer thread.","title":"JVM Primer Part 2 - Debugging memory issues"},{"content":"This series is a summary of Oracle\u0026rsquo;s JVM troubleshooting course which gives an overview on JVM memory management, Hotspot VM\u0026rsquo;s garbage collection options, various memory errors and how to troubleshoot them.\nIn this post (part 1), we will have a look at how JVM manages memory and its different garbage collectors.\nYou can find Part 2 here\nJVM Memory Management Overview The JVM provides automatic memory management to free the programmer from manually managing memory. New objects are allocated on heap memory. A root set consists of pointers to external memory, static variables, threads, JNI references and internal JVM structures. Objects directly reachable from the root set must be kept in heap. Objects reachable from any of the reachable objects must also be in heap. This group of objects are the only ones which can be used by a program. The unreachable objects (garbage) are removed using a process called garbage collection (GC). Reachable objects are compacted i.e moved to contiguous space in heap. This is important as otherwise, the heap will become fragmented.\nGenerational GC and Memory Spaces in Hotspot When the JVM starts, it requests some memory from the OS. This memory is divided into various spaces.\nMemory spaces in JVM prior to JDK 8\nSeparate pools hold objects of diff age ranges JVM\u0026rsquo;s GC is generational and is based on the hypothesis that: Most objects die young Few references from older to younger objects There are 2 generations of objects: young : small and collected frequently (minor collection). Objects which survive a threshold number of GCs move to old generation. old : large, collected infrequently (major collection = Full GC) Prior to JDK 8, there was also a permanent generation which was for storing class representations and metadata, interned strings and class statics. This was replaced by meta-space in JDK 8 and later. Meta-space is allocated in native memory. It is managed through JVM options MetaspaceSize for initial size and MaxMetaspaceSize for maximum. If UseCompressedClassPointers is enabled, 2 areas of memory are used for storing classes and their metadata - meta-space and compressed class space. 64 bit class pointers represented with 32 bit offsets to save space. Class metadata is referenced by 32 bit offsets stored in compressed class space. By default, compressed class space is 1 GB. Code cache is used to store compiled code generated by JIT (Just in time optimizer), allocated out of native memory and managed by Code Cache Sweeper Garbage Collectors in Hotspot JVM The JVM has different garbage collection methods for different generations of objects. Some of them are described below:\nYoung generation collection Serial - Stop-the-world (STW), copying collector, single threaded ParNew - STW, copying collector, multiple GC threads Parallel Scavenge - STW, copying collector, multiple GC threads Old generation collection Serial Old - STW, mark-sweep-compact collector, single threaded CMS - Mostly concurrent, low pause Parallel Old - compacting collector, multiple GC threads G1 : designed for large heaps and offers predictable short pauses. Has different memory layout for generations Same collector for all generations GC options for JDK These are the option flags passed to JVM for specifying which GC to use:\nUseSerialGC : Serial + SerialOld UseParNewGC : ParNew + SerialOld . In JDK 9, uses CMS for old gen UseConcMarkSweepGC : ParNew + CMS + SerialOld CMS used most of time to collect old generation. SerialOld used when concurrent mode failure occurs. CMS performs most work in concurrent with application threads. No heap compaction leads to fragmentation. Has floating garbage and requires larger heap sizes. Free space maintained as linked lists. Allocation expensive compared to bump-the-pointer allocations. Additional overhead on young collections Deprecated in JDK 9 UseParallelGC : Parallel Scavenge + Parallel Old. Maximizes throughput. Default GC till JDK 9 UseG1GC - G1 for both generations Server style GC for multi-core machines with large memory Low GC pauses with high probability while trying for high throughput Compacting collector. Low pauses without fragmentation Better GC ergonomics. Parallel threads and some tasks are concurrent with application threads Available since JDK 7u4 and default in JDK 9 For more detailed information on tuning the garbage collector, read the official GC Tuning Guide\nMinor GC or How young generation is collected: When Eden space in young gen is full, reachable objects are marked and moved to the ToSurvivorSpace Objects in FromSurvivor space that are reachable are moved to ToSurvivorSpace Objects in FromSurvivor space that have crossed the threshold are promoted to the old generation Eden becomes empty and is ready for new allocations To and From Survivor Spaces are switched Notes on Mark-Sweep-Compact collector (Serial Old): Mark phase : marks all live objects Sweep phase : sweeps over heap identifying garbage Slide phase : GC performs a sliding compaction by sliding live objects to the start of the heap ","permalink":"https://rrampage.github.io/2018/05/15/a-primer-on-jvm-memory-management-and-troubleshooting-1/","summary":"This series is a summary of Oracle\u0026rsquo;s JVM troubleshooting course which gives an overview on JVM memory management, Hotspot VM\u0026rsquo;s garbage collection options, various memory errors and how to troubleshoot them.\nIn this post (part 1), we will have a look at how JVM manages memory and its different garbage collectors.\nYou can find Part 2 here\nJVM Memory Management Overview The JVM provides automatic memory management to free the programmer from manually managing memory. New objects are allocated on heap memory. A root set consists of pointers to external memory, static variables, threads, JNI references and internal JVM structures. Objects directly reachable from the root set must be kept in heap. Objects reachable from any of the reachable objects must also be in heap. This group of objects are the only ones which can be used by a program. The unreachable objects (garbage) are removed using a process called garbage collection (GC). Reachable objects are compacted i.e moved to contiguous space in heap.","title":"A Primer on JVM Memory Management and Troubleshooting - 1"},{"content":"Snake case and Camel case are conventions of naming variables, functions and classes. Most teams and projects prescribe a particular case in their style guides.\nExamples of camel case:\nMyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher Examples of snake case:\nadd matrix_add diagonal_matrix_add pseudo_inverse If we want to convert back and forth between these cases, we must look for the points of interest - the word boundaries. Camel case boundaries have the first letter capitalized while the snake case word boundaries have an _.\nSnake case to camel case Here is a regular expression for finding out the _ and the first letter in the next word:\n(.*?)_([a-zA-Z]) This regex has 2 parts:\n(.*?) finds everything upto the _.\nThe \u0026lsquo;.\u0026rsquo; means any character. \u0026lsquo;*\u0026rsquo; stands for match 0 or more instances \u0026lsquo;?\u0026rsquo; stands for non-greedy match. We must use \u0026lsquo;?\u0026rsquo; in the pattern because the regex engine will try to match as much as possible by default. So, if we use just (.*), the whole word will be consumed and nothing will be left for the rest of the pattern. \u0026lsquo;()\u0026rsquo; stand for a group. A group is a way of saving a part of the match for later. Together, they mean that find all characters upto the first \u0026lsquo;_\u0026rsquo; and capture them in a group. ([a-zA-Z]) finds the first alphabet after the _. We need this to convert to upper case for Camel case.\nThe Python code below converts words which are in snake case to camel case:\nimport re REG = r\u0026#34;(.*?)_([a-zA-Z])\u0026#34; def camel(match): return match.group(1) + match.group(2).upper() def camel_upper(match): return match.group(1)[0].upper() + match.group(1)[1:] + match.group(2).upper() words = \u0026#34;\u0026#34;\u0026#34;add matrix_add diagonal_matrix_add pseudo_inverse\u0026#34;\u0026#34;\u0026#34;.splitlines() results = [re.sub(REG, camel, w, 0) for w in words] print(results) # Output: # [\u0026#39;add\u0026#39;, \u0026#39;matrixAdd\u0026#39;, \u0026#39;diagonalMatrixAdd\u0026#39;, \u0026#39;pseudoInverse\u0026#39;] We use the regex we constructed earlier and the re.sub method to substitute our matched words. We pass a method called camel as an argument. This method allows us to change the case of the letter in the second group and keep the first group unchanged. Notice that the first letter can be either lower or upper depending on whether it is a variable or method (lower) or a class (upper). The camel_upper method can be used for class names.\nCamel case to snake case Similarly, for converting from camel to snake case, the regex is:\n(.+?)([A-Z]) And the Python code :\nimport re REG = r\u0026#34;(.+?)([A-Z])\u0026#34; def snake(match): return match.group(1).lower() + \u0026#34;_\u0026#34; + match.group(2).lower() words = \u0026#34;\u0026#34;\u0026#34;MyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher\u0026#34;\u0026#34;\u0026#34;.splitlines() results = [re.sub(REG, snake, w, 0) for w in words] print(results) # Output # [\u0026#39;my_class\u0026#39;, \u0026#39;my_class_factory\u0026#39;, \u0026#39;my_class_factory_builder\u0026#39;, \u0026#39;my_class_factory_builder_impl\u0026#39;, \u0026#39;my_instance\u0026#39;, \u0026#39;my_instance2\u0026#39;, \u0026#39;abc\u0026#39;, \u0026#39;pattern_matcher\u0026#39;] ","permalink":"https://rrampage.github.io/2018/05/09/snake-case-to-camel-case-and-back-using-regular-expressions-and-python/","summary":"Snake case and Camel case are conventions of naming variables, functions and classes. Most teams and projects prescribe a particular case in their style guides.\nExamples of camel case:\nMyClass MyClassFactory MyClassFactoryBuilder MyClassFactoryBuilderImpl myInstance myInstance2 abc patternMatcher Examples of snake case:\nadd matrix_add diagonal_matrix_add pseudo_inverse If we want to convert back and forth between these cases, we must look for the points of interest - the word boundaries. Camel case boundaries have the first letter capitalized while the snake case word boundaries have an _.\nSnake case to camel case Here is a regular expression for finding out the _ and the first letter in the next word:\n(.*?)_([a-zA-Z]) This regex has 2 parts:\n(.*?) finds everything upto the _.\nThe \u0026lsquo;.\u0026rsquo; means any character. \u0026lsquo;*\u0026rsquo; stands for match 0 or more instances \u0026lsquo;?\u0026rsquo; stands for non-greedy match. We must use \u0026lsquo;?\u0026rsquo; in the pattern because the regex engine will try to match as much as possible by default. So, if we use just (.","title":"Snake case to camel case and back using regular expressions and Python"},{"content":"Background Today, I resumed a rust project of mine after a long time. In order to check my last working code, I ran cargo run. But it refused to run with error message:\n....\u0026#34;-Wl,-Bdynamic\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;dl\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;gcc_s\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;c\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;m\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; = note: /usr/bin/ld: cannot find Scrt1.o: No such file or directory collect2: error: ld returned 1 exit status Linker Issues! ld is used to link libraries. So, the error was not in the code but in the linking phase. I googled the error and the solution was to have build-essential package installed. But the package was already installed on my machine (it is one of the first packages I install on any development machine).\nSome more googling revealed that cargo uses the system cc linker to link to the C runtime. Running which cc gave me $HOME/anaconda3/bin/cc. This cc is part of my Anaconda root environment. (Anaconda is a package manager for scientific computing packages. It is a convenient way for installing multiple versions of packages in different environments).\nOn Linux, the linker knows where to find the required libraries using the shared library cache. I ran ldconfig -v to refresh it and then try again. Same error!\nIt is possible to explicitly list directories to include using LD_LIBRARY_PATH environment variable. I tried setting the LD_LIBRARY_PATH to point to the required directory and then run cargo as LD_LIBRARY_PATH=DIR cargo build -v. But it gave the same error.\nI thought that cargo must be setting the linker value somewhere, so instead let me try directly compiling with rustc. Even that gave the same error. With this, I eliminated the possibility of some environment variable only affecting cargo.\nMore googling! Further searching for the error with \u0026ldquo;rust\u0026rdquo; added showed me results of people having trouble cross-compiling. From this, I learned that cargo has different targets i.e different instruction sets (e,g x86-64, arm, x86, mips), different OSs (e.g linux, windows, freebsd) and different C runtimes (e.g glibc, musl, msvc). The Rust documentation on cargo mentioned that this is called a target triple. The Cargo book mentioned that you can direct cargo to explicitly use a particular linker using RUSTFLAGS environment variable.\nSince I am only building for my machine, I had to find out the exact value of the target. Rust gives an exhaustive list of all supported targets by running rustc --print target-list. My target was x86_64-unknown-linux-gnu.\nIt is possible to pass a linker to cargo explicitly as RUSTFLAGS=\u0026quot;-C linker=x86_64-unknown-linux-gnu\u0026quot; cargo build -v. It worked!\nAll-time fix! I do not want to do this every time I run cargo. The Cargo book says that cargo uses a global config file in $HOME/.cargo/config.\nI added the following to the file:\n# Specify which linker to use for this target [target.x86_64-unknown-linux-gnu] linker = \u0026#34;x86_64-linux-gnu-gcc\u0026#34; Now, cargo build works without issues.\n","permalink":"https://rrampage.github.io/2018/05/09/cargo-refused-to-build-my-project-a-rust-debugging-story/","summary":"Background Today, I resumed a rust project of mine after a long time. In order to check my last working code, I ran cargo run. But it refused to run with error message:\n....\u0026#34;-Wl,-Bdynamic\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;dl\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;gcc_s\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;c\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;m\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;rt\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;pthread\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; \u0026#34;-l\u0026#34; \u0026#34;util\u0026#34; = note: /usr/bin/ld: cannot find Scrt1.o: No such file or directory collect2: error: ld returned 1 exit status Linker Issues! ld is used to link libraries. So, the error was not in the code but in the linking phase. I googled the error and the solution was to have build-essential package installed. But the package was already installed on my machine (it is one of the first packages I install on any development machine).\nSome more googling revealed that cargo uses the system cc linker to link to the C runtime. Running which cc gave me $HOME/anaconda3/bin/cc. This cc is part of my Anaconda root environment.","title":"Cargo refused to build my project - A Rust debugging story!"},{"content":"Many times, smoothly running processes stop working mysteriously. You open the logs and see what is happening, only to find that even the logs have stopped updating. But the process itself is running. You SSH to the server and type cd TAB. Bash weeps \u0026ldquo;Unable to create temporary file\u0026rdquo;. The machine is out of disk space\u0026hellip;\nHere is a checklist to make disk space debugging easier, using standard Linux utilities so you can get started without having to install anything extra:\ndf -h command gives you an overview in a readable format about the number of disks mounted and their total and available capacities. To get an idea of which folders/directories are eating up the maximum space, try out du -ch / | sort -h | tail -n 30. This gives you the 30 most space consuming directories. If you already know which directories generate maximum disk output e.g logs and temp files, you can replace the \u0026lsquo;/\u0026rsquo; with your directory (DIR) and run the command as du -ch DIR | sort -h | tail -n 30 Now that we have identified the directories with maximum space consumed, we may need to delete some files and get our process going again. The rm command is your friend here. You can delete old logs and temporary files to free up space. Many times, the culprit is a single large file which is already in use by a program e.g catalina.out by Apache Tomcat. If you want to free up space without shutting down the process, the truncate command will help you out. Example: truncate -s0 BIG_LOG.log. This will truncate the file to 0 bytes and still allow the other process to use it without issues (standard Unix permissions apply) Sometimes, you delete files and still, the space does not seem to be recovered. This can be because some process is still holding on to the file descriptor of the deleted file. Once these processes are stopped, the space will be recovered. The lsof command will help you out here. It stands for list open files. You can find out which processes are using deleted files as follows: lsof | grep deleted | grep OLD_FILENAME. The lsof command gives you the process name and the process id so you can run kill on the process. If you do not know the name of the deleted file, you can still run lsof | grep deleted and see the output to check for any familiar file / process. Finally, keep in mind that disk space is one of the metrics you should monitor on your server. This checklist must be used in a pinch. If you find yourself constantly having disk space issues, the solution is to set up periodic deletion/rotation of old log files, alerts when the disk space reaches a particular threshold or to increase the disk size if your processes require a lot of disk space e.g Kafka, MySQL and other databases.\nLet me know if there are some other tools I am missing out on and your experiences dealing with disk space issues!\n","permalink":"https://rrampage.github.io/2018/05/04/disk-space-debugging-checklist/","summary":"Many times, smoothly running processes stop working mysteriously. You open the logs and see what is happening, only to find that even the logs have stopped updating. But the process itself is running. You SSH to the server and type cd TAB. Bash weeps \u0026ldquo;Unable to create temporary file\u0026rdquo;. The machine is out of disk space\u0026hellip;\nHere is a checklist to make disk space debugging easier, using standard Linux utilities so you can get started without having to install anything extra:\ndf -h command gives you an overview in a readable format about the number of disks mounted and their total and available capacities. To get an idea of which folders/directories are eating up the maximum space, try out du -ch / | sort -h | tail -n 30. This gives you the 30 most space consuming directories. If you already know which directories generate maximum disk output e.g logs and temp files, you can replace the \u0026lsquo;/\u0026rsquo; with your directory (DIR) and run the command as du -ch DIR | sort -h | tail -n 30 Now that we have identified the directories with maximum space consumed, we may need to delete some files and get our process going again.","title":"Disk Space Debugging Checklist"},{"content":"Hello World!\n","permalink":"https://rrampage.github.io/2014/03/03/hello-world/","summary":"Hello World!","title":"Hello World"},{"content":"About this blog: the delights and frustrations of programming new things I learn/stumble across while coding interesting concepts/resources I come across trying to explain a few topics About Me I am a software developer. I work on mostly backend stuff. I blog occasionally here or crosspost to dev.to. You can reach out to me via various websites in the footer.\n💬 Ask me about \u0026hellip; Bash, sed, awk, GNU Make, jq Linux Postgres/MySQL/SQLite Java/Kotlin, JOOQ, Dropwizard Solr \u0026amp; Elasticsearch ArangoDB Nginx \u0026amp; Openresty State machines, Regexes, State charts 📫 How to reach me: Mastodon LinkedIn Twitter Software powering this blog: Hugo Theme - PaperMod Github pages ","permalink":"https://rrampage.github.io/about/","summary":"About this blog: the delights and frustrations of programming new things I learn/stumble across while coding interesting concepts/resources I come across trying to explain a few topics About Me I am a software developer. I work on mostly backend stuff. I blog occasionally here or crosspost to dev.to. You can reach out to me via various websites in the footer.\n💬 Ask me about \u0026hellip; Bash, sed, awk, GNU Make, jq Linux Postgres/MySQL/SQLite Java/Kotlin, JOOQ, Dropwizard Solr \u0026amp; Elasticsearch ArangoDB Nginx \u0026amp; Openresty State machines, Regexes, State charts 📫 How to reach me: Mastodon LinkedIn Twitter Software powering this blog: Hugo Theme - PaperMod Github pages ","title":"About"}]